{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_N89t2EAO9S"
      },
      "source": [
        "# Code for normal CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1nGomruAO9U",
        "outputId": "4d5c7aa4-eeb7-40d2-d32c-39a09a6ed813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (92, 88, 1)\n",
            "y_train_correct shape: (92,)\n",
            "y_train_error shape: (92, 3)\n",
            "X_test shape: (24, 88, 1)\n",
            "y_test_correct shape: (24,)\n",
            "y_test_error shape: (24, 3)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense\n",
        "import joblib\n",
        "\n",
        "# Step 1: Load CSV file\n",
        "data = pd.read_csv('/content/FINALLY_PLANK.csv')\n",
        "\n",
        "# Step 2: Separate keypoints and labels\n",
        "keypoints = data.iloc[:, 1:89].values  # Skip the first column (frame name) and take the next 88 columns\n",
        "correct_label = data['pose-label'].values  # Binary labels: 0 (incorrect), 1 (correct)\n",
        "error_type = data['error-label'].fillna('None').values  # Error types: None, Too-high-plank, Too-low-plank\n",
        "\n",
        "# Step 3: Normalize keypoints (Min-Max Scaling)\n",
        "scaler = MinMaxScaler()\n",
        "keypoints = scaler.fit_transform(keypoints)\n",
        "\n",
        "# Save the scaler for later use in backend\n",
        "joblib.dump(scaler, '/content/scaler.pkl')\n",
        "\n",
        "# Step 4: Reshape keypoints to (88, 1) for CNN input\n",
        "keypoints = keypoints.reshape(-1, 88, 1)\n",
        "\n",
        "# Step 5: Convert Error Type labels\n",
        "encoder = LabelEncoder()\n",
        "error_type_encoded = encoder.fit_transform(error_type)  # Encode error types as integers\n",
        "error_type_categorical = to_categorical(error_type_encoded)  # One-hot encode for categorical model\n",
        "\n",
        "# Save the label encoder for backend use\n",
        "joblib.dump(encoder, '/content/encoder.pkl')\n",
        "\n",
        "# Step 6: Split data into training and testing sets\n",
        "X_train, X_test, y_train_correct, y_test_correct, y_train_error, y_test_error = train_test_split(\n",
        "    keypoints, correct_label, error_type_categorical, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Print data shapes to verify\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train_correct shape: {y_train_correct.shape}\")\n",
        "print(f\"y_train_error shape: {y_train_error.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test_correct shape: {y_test_correct.shape}\")\n",
        "print(f\"y_test_error shape: {y_test_error.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "cjosmcxFOzVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_cnn_correct_incorrect():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(88, 1)),  # 88 keypoints as input\n",
        "        layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Step 1: Build the model\n",
        "model_1 = build_cnn_correct_incorrect()\n",
        "\n",
        "# Step 3: Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "history_1 = model_1.fit(\n",
        "    X_train, y_train_correct,\n",
        "    validation_data=(X_test, y_test_correct),\n",
        "    epochs=1000, batch_size=32, callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "model_1.save('/content/cnn_pose-label.keras')"
      ],
      "metadata": {
        "id": "-q8uB5kpZZAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f78d90-32b3-45de-929f-bcfa041d9515"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.4796 - loss: 0.6865 - val_accuracy: 0.6250 - val_loss: 0.6437\n",
            "Epoch 2/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6644 - loss: 0.6028 - val_accuracy: 0.6250 - val_loss: 0.5923\n",
            "Epoch 3/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6386 - loss: 0.5860 - val_accuracy: 0.6667 - val_loss: 0.5440\n",
            "Epoch 4/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8327 - loss: 0.5243 - val_accuracy: 0.7083 - val_loss: 0.5209\n",
            "Epoch 5/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7009 - loss: 0.5174 - val_accuracy: 0.7917 - val_loss: 0.4988\n",
            "Epoch 6/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6861 - loss: 0.5259 - val_accuracy: 0.7917 - val_loss: 0.4836\n",
            "Epoch 7/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6994 - loss: 0.4876 - val_accuracy: 0.7917 - val_loss: 0.4876\n",
            "Epoch 8/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7298 - loss: 0.4873 - val_accuracy: 0.7917 - val_loss: 0.4957\n",
            "Epoch 9/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6844 - loss: 0.5083 - val_accuracy: 0.8333 - val_loss: 0.4983\n",
            "Epoch 10/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7811 - loss: 0.4565 - val_accuracy: 0.7917 - val_loss: 0.5044\n",
            "Epoch 11/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8497 - loss: 0.4262 - val_accuracy: 0.7917 - val_loss: 0.5093\n",
            "Epoch 12/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8325 - loss: 0.4359 - val_accuracy: 0.7917 - val_loss: 0.5052\n",
            "Epoch 13/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8247 - loss: 0.4027 - val_accuracy: 0.7917 - val_loss: 0.5186\n",
            "Epoch 14/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8684 - loss: 0.3880 - val_accuracy: 0.7083 - val_loss: 0.5264\n",
            "Epoch 15/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8575 - loss: 0.3895 - val_accuracy: 0.7083 - val_loss: 0.5358\n",
            "Epoch 16/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8529 - loss: 0.3508 - val_accuracy: 0.7500 - val_loss: 0.5560\n",
            "Epoch 17/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8021 - loss: 0.3510 - val_accuracy: 0.7083 - val_loss: 0.5489\n",
            "Epoch 18/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8653 - loss: 0.3284 - val_accuracy: 0.7083 - val_loss: 0.5526\n",
            "Epoch 19/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8645 - loss: 0.3430 - val_accuracy: 0.7083 - val_loss: 0.5642\n",
            "Epoch 20/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8544 - loss: 0.3173 - val_accuracy: 0.7083 - val_loss: 0.5645\n",
            "Epoch 21/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8387 - loss: 0.3519 - val_accuracy: 0.7500 - val_loss: 0.5793\n",
            "Epoch 22/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8536 - loss: 0.3158 - val_accuracy: 0.7083 - val_loss: 0.5703\n",
            "Epoch 23/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8668 - loss: 0.3059 - val_accuracy: 0.7083 - val_loss: 0.5842\n",
            "Epoch 24/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8551 - loss: 0.3112 - val_accuracy: 0.7500 - val_loss: 0.5922\n",
            "Epoch 25/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8879 - loss: 0.2930 - val_accuracy: 0.7083 - val_loss: 0.5854\n",
            "Epoch 26/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8903 - loss: 0.2614 - val_accuracy: 0.7083 - val_loss: 0.5896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "# Model 1 predictions\n",
        "y_pred_model_1 = model_1.predict(X_test)  # Assuming 'model_1' is the trained model\n",
        "y_pred_model_1 = (y_pred_model_1 > 0.5)  # If binary classification, otherwise use softmax for multi-class\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_correct, y_pred_model_1)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test_correct, y_pred_model_1)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_test_correct, y_pred_model_1)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test_correct, y_pred_model_1)\n",
        "\n",
        "print(f\"Model CNN Evaluation:\\n\"\n",
        "      f\"Accuracy: {accuracy}\\n\"\n",
        "      f\"Precision: {precision}\\n\"\n",
        "      f\"Recall: {recall}\\n\"\n",
        "      f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNj7EkmvVlMB",
        "outputId": "74f33d18-7989-41e4-f500-5b61bce8e356"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "Model CNN Evaluation:\n",
            "Accuracy: 0.7916666666666666\n",
            "Precision: 0.75\n",
            "Recall: 0.6666666666666666\n",
            "F1 Score: 0.7058823529411765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew1b3XQTAO9V",
        "outputId": "80c7ad26-c4c7-4a0a-b17c-d928bb3b1b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train_error_incorrect before one-hot encoding: (59, 3)\n",
            "Shape of y_test_error_incorrect before one-hot encoding: (15, 3)\n",
            "Shape of y_train_error_incorrect after one-hot encoding: (59, 3)\n",
            "Shape of y_test_error_incorrect after one-hot encoding: (15, 3)\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 352ms/step - accuracy: 0.5056 - loss: 1.0152 - val_accuracy: 0.4667 - val_loss: 0.7871\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5907 - loss: 0.7779 - val_accuracy: 0.4000 - val_loss: 0.7265\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4735 - loss: 0.7066 - val_accuracy: 0.6000 - val_loss: 0.6446\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5630 - loss: 0.6645 - val_accuracy: 0.7333 - val_loss: 0.6380\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6916 - loss: 0.6271 - val_accuracy: 0.5333 - val_loss: 0.6595\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7350 - loss: 0.6046 - val_accuracy: 0.7333 - val_loss: 0.6201\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7567 - loss: 0.5722 - val_accuracy: 0.8000 - val_loss: 0.5759\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7689 - loss: 0.5591 - val_accuracy: 0.8000 - val_loss: 0.5714\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7594 - loss: 0.5260 - val_accuracy: 0.7333 - val_loss: 0.5548\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8028 - loss: 0.5124 - val_accuracy: 0.7333 - val_loss: 0.5387\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8123 - loss: 0.4890 - val_accuracy: 0.7333 - val_loss: 0.5456\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8358 - loss: 0.4522 - val_accuracy: 0.8000 - val_loss: 0.4926\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8575 - loss: 0.4357 - val_accuracy: 0.7333 - val_loss: 0.4889\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9218 - loss: 0.3795 - val_accuracy: 0.7333 - val_loss: 0.5018\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9227 - loss: 0.3771 - val_accuracy: 0.7333 - val_loss: 0.4635\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9444 - loss: 0.3384 - val_accuracy: 0.8667 - val_loss: 0.4438\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9444 - loss: 0.3236 - val_accuracy: 0.7333 - val_loss: 0.4392\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9331 - loss: 0.2934 - val_accuracy: 0.7333 - val_loss: 0.4655\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9227 - loss: 0.3022 - val_accuracy: 0.8667 - val_loss: 0.4030\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9444 - loss: 0.2748 - val_accuracy: 0.8667 - val_loss: 0.3878\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9783 - loss: 0.2247 - val_accuracy: 0.7333 - val_loss: 0.4225\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9661 - loss: 0.2159 - val_accuracy: 0.8000 - val_loss: 0.3630\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9670 - loss: 0.2001 - val_accuracy: 0.9333 - val_loss: 0.3625\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9670 - loss: 0.1907 - val_accuracy: 0.8667 - val_loss: 0.3500\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9774 - loss: 0.1592 - val_accuracy: 0.7333 - val_loss: 0.3692\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.1524 - val_accuracy: 0.8667 - val_loss: 0.3399\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9774 - loss: 0.1450 - val_accuracy: 0.8667 - val_loss: 0.3466\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.1450 - val_accuracy: 0.8667 - val_loss: 0.3375\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9887 - loss: 0.1187 - val_accuracy: 0.8667 - val_loss: 0.3108\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.1050 - val_accuracy: 0.9333 - val_loss: 0.3241\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9783 - loss: 0.1080 - val_accuracy: 0.8667 - val_loss: 0.2942\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0840 - val_accuracy: 0.8667 - val_loss: 0.2940\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0806 - val_accuracy: 0.8667 - val_loss: 0.2795\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0652 - val_accuracy: 0.8667 - val_loss: 0.2882\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0650 - val_accuracy: 0.8667 - val_loss: 0.2906\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0613 - val_accuracy: 0.8667 - val_loss: 0.2834\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0519 - val_accuracy: 0.8667 - val_loss: 0.2835\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0485 - val_accuracy: 0.8667 - val_loss: 0.2828\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0416 - val_accuracy: 0.8667 - val_loss: 0.2979\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0484 - val_accuracy: 0.8667 - val_loss: 0.2857\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0400 - val_accuracy: 0.8667 - val_loss: 0.2733\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0396 - val_accuracy: 0.8667 - val_loss: 0.2692\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0387 - val_accuracy: 0.8667 - val_loss: 0.2819\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0368 - val_accuracy: 0.8667 - val_loss: 0.2804\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0294 - val_accuracy: 0.8667 - val_loss: 0.2542\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0316 - val_accuracy: 0.8667 - val_loss: 0.2665\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0355 - val_accuracy: 0.8667 - val_loss: 0.2631\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0221 - val_accuracy: 0.8667 - val_loss: 0.2921\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0253 - val_accuracy: 0.8667 - val_loss: 0.2796\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.8667 - val_loss: 0.2682\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Updated build model function\n",
        "def build_cnn_error_classification():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(88, 1)),  # 88 keypoints as input\n",
        "        layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(3, activation='softmax')  # Multi-class classification output (3 classes)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Filter only incorrect samples for training Model 2\n",
        "X_train_incorrect = X_train[y_train_correct == 0]\n",
        "X_test_incorrect = X_test[y_test_correct == 0]\n",
        "y_train_error_incorrect = y_train_error[y_train_correct == 0]\n",
        "y_test_error_incorrect = y_test_error[y_test_correct == 0]\n",
        "\n",
        "# Check and reshape if necessary\n",
        "print(f\"Shape of y_train_error_incorrect before one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect before one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Only apply one-hot encoding if they are not already encoded\n",
        "if len(y_train_error_incorrect.shape) == 1:\n",
        "    y_train_error_incorrect = to_categorical(y_train_error_incorrect, num_classes=3)\n",
        "    y_test_error_incorrect = to_categorical(y_test_error_incorrect, num_classes=3)\n",
        "\n",
        "# Check shapes after one-hot encoding\n",
        "print(f\"Shape of y_train_error_incorrect after one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect after one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Train the model\n",
        "model_2 = build_cnn_error_classification()\n",
        "\n",
        "history_2 = model_2.fit(\n",
        "    X_train_incorrect, y_train_error_incorrect,\n",
        "    validation_data=(X_test_incorrect, y_test_error_incorrect),\n",
        "    epochs=50, batch_size=32\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model_2.save('/content/cnn_error-label.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convert true labels to class indices if they are one-hot encoded\n",
        "y_test_error_incorrect_class = np.argmax(y_test_error_incorrect, axis=1)\n",
        "\n",
        "# Model 2 predictions (assuming the model outputs class probabilities)\n",
        "y_pred_model_2 = model_2.predict(X_test_incorrect)  # Your model's predictions\n",
        "y_pred_model_2 = np.argmax(y_pred_model_2, axis=1)  # Convert predictions to class indices\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_error_incorrect_class, y_pred_model_2)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'],\n",
        "            yticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'])\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# F1-score for each error type (class)\n",
        "f1_error_1 = f1_score(y_test_error_incorrect_class, y_pred_model_2, labels=[0], average='micro')  # Error Type 1\n",
        "f1_error_2 = f1_score(y_test_error_incorrect_class, y_pred_model_2, labels=[1], average='micro')  # Error Type 2\n",
        "f1_error_3 = f1_score(y_test_error_incorrect_class, y_pred_model_2, labels=[2], average='micro')  # Error Type 3\n",
        "\n",
        "print(f\"Model CNN Evaluation:\\n\"\n",
        "      f\"F1 Score for Error Type 1: {f1_error_1}\\n\"\n",
        "      f\"F1 Score for Error Type 2: {f1_error_2}\\n\"\n",
        "      f\"F1 Score for Error Type 3: {f1_error_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "S2w7iUqlWV38",
        "outputId": "6acb15de-73f0-4973-b8e2-887d6fc92715"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model CNN Evaluation:\n",
            "F1 Score for Error Type 1: 0.0\n",
            "F1 Score for Error Type 2: 0.8888888888888888\n",
            "F1 Score for Error Type 3: 0.8333333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN with Attention"
      ],
      "metadata": {
        "id": "dfe1znjTO3xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_cnn_with_attention_correct_incorrect():\n",
        "    inputs = layers.Input(shape=(88, 1))\n",
        "    x = layers.Conv1D(32, kernel_size=3, activation='relu')(inputs)\n",
        "    x = layers.Conv1D(64, kernel_size=3, activation='relu')(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "    attention = layers.Attention()([x, x])  # Self-attention\n",
        "    x = layers.Flatten()(attention)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Step 1: Build the model\n",
        "model_3 = build_cnn_with_attention_correct_incorrect()\n",
        "\n",
        "# Step 3: Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "history_3 = model_3.fit(\n",
        "    X_train, y_train_correct,\n",
        "    validation_data=(X_test, y_test_correct),\n",
        "    epochs=1000, batch_size=32, callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "model_3.save('/content/cnn-with-attention_pose-label.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUUWEHnzO6Le",
        "outputId": "0046cfe2-4be8-4dcf-8396-ba75cbf72ae1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - accuracy: 0.4507 - loss: 0.6851 - val_accuracy: 0.6250 - val_loss: 0.6687\n",
            "Epoch 2/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6332 - loss: 0.6637 - val_accuracy: 0.6250 - val_loss: 0.6587\n",
            "Epoch 3/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6449 - loss: 0.6458 - val_accuracy: 0.6250 - val_loss: 0.6507\n",
            "Epoch 4/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5941 - loss: 0.6715 - val_accuracy: 0.6250 - val_loss: 0.6427\n",
            "Epoch 5/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6214 - loss: 0.6447 - val_accuracy: 0.6250 - val_loss: 0.6416\n",
            "Epoch 6/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6332 - loss: 0.6347 - val_accuracy: 0.6250 - val_loss: 0.6314\n",
            "Epoch 7/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6332 - loss: 0.6283 - val_accuracy: 0.6250 - val_loss: 0.6139\n",
            "Epoch 8/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6566 - loss: 0.5997 - val_accuracy: 0.6250 - val_loss: 0.6009\n",
            "Epoch 9/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6683 - loss: 0.5798 - val_accuracy: 0.6667 - val_loss: 0.5905\n",
            "Epoch 10/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6097 - loss: 0.6107 - val_accuracy: 0.6667 - val_loss: 0.5750\n",
            "Epoch 11/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6761 - loss: 0.5656 - val_accuracy: 0.6667 - val_loss: 0.5803\n",
            "Epoch 12/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6401 - loss: 0.5731 - val_accuracy: 0.6667 - val_loss: 0.5589\n",
            "Epoch 13/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6440 - loss: 0.5703 - val_accuracy: 0.6667 - val_loss: 0.5495\n",
            "Epoch 14/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6292 - loss: 0.5514 - val_accuracy: 0.6667 - val_loss: 0.5452\n",
            "Epoch 15/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6675 - loss: 0.5315 - val_accuracy: 0.7083 - val_loss: 0.5406\n",
            "Epoch 16/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6675 - loss: 0.5257 - val_accuracy: 0.7917 - val_loss: 0.5281\n",
            "Epoch 17/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7430 - loss: 0.5325 - val_accuracy: 0.7917 - val_loss: 0.5257\n",
            "Epoch 18/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7011 - loss: 0.5038 - val_accuracy: 0.7500 - val_loss: 0.5346\n",
            "Epoch 19/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6720 - loss: 0.5496 - val_accuracy: 0.7917 - val_loss: 0.5185\n",
            "Epoch 20/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7626 - loss: 0.4944 - val_accuracy: 0.7500 - val_loss: 0.5244\n",
            "Epoch 21/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6807 - loss: 0.5556 - val_accuracy: 0.7500 - val_loss: 0.5315\n",
            "Epoch 22/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6948 - loss: 0.5000 - val_accuracy: 0.7917 - val_loss: 0.5180\n",
            "Epoch 23/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7461 - loss: 0.5341 - val_accuracy: 0.8333 - val_loss: 0.5164\n",
            "Epoch 24/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7469 - loss: 0.4997 - val_accuracy: 0.7083 - val_loss: 0.5433\n",
            "Epoch 25/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7244 - loss: 0.5186 - val_accuracy: 0.7083 - val_loss: 0.5435\n",
            "Epoch 26/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6892 - loss: 0.5113 - val_accuracy: 0.7917 - val_loss: 0.5150\n",
            "Epoch 27/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7515 - loss: 0.5284 - val_accuracy: 0.8333 - val_loss: 0.5159\n",
            "Epoch 28/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6822 - loss: 0.5280 - val_accuracy: 0.7500 - val_loss: 0.5443\n",
            "Epoch 29/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6675 - loss: 0.5427 - val_accuracy: 0.7500 - val_loss: 0.5212\n",
            "Epoch 30/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7172 - loss: 0.5244 - val_accuracy: 0.8333 - val_loss: 0.5082\n",
            "Epoch 31/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7133 - loss: 0.5265 - val_accuracy: 0.8333 - val_loss: 0.5133\n",
            "Epoch 32/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7244 - loss: 0.5058 - val_accuracy: 0.7917 - val_loss: 0.5229\n",
            "Epoch 33/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6853 - loss: 0.5121 - val_accuracy: 0.8333 - val_loss: 0.5061\n",
            "Epoch 34/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7352 - loss: 0.4906 - val_accuracy: 0.8333 - val_loss: 0.5064\n",
            "Epoch 35/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7773 - loss: 0.4780 - val_accuracy: 0.8333 - val_loss: 0.5037\n",
            "Epoch 36/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7743 - loss: 0.4625 - val_accuracy: 0.7500 - val_loss: 0.5343\n",
            "Epoch 37/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6955 - loss: 0.5047 - val_accuracy: 0.8333 - val_loss: 0.5060\n",
            "Epoch 38/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7305 - loss: 0.5133 - val_accuracy: 0.8333 - val_loss: 0.5109\n",
            "Epoch 39/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6962 - loss: 0.5187 - val_accuracy: 0.7500 - val_loss: 0.5282\n",
            "Epoch 40/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7298 - loss: 0.4856 - val_accuracy: 0.8333 - val_loss: 0.5118\n",
            "Epoch 41/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7407 - loss: 0.4999 - val_accuracy: 0.7917 - val_loss: 0.5001\n",
            "Epoch 42/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6868 - loss: 0.5210 - val_accuracy: 0.7917 - val_loss: 0.5226\n",
            "Epoch 43/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7368 - loss: 0.4642 - val_accuracy: 0.7917 - val_loss: 0.5249\n",
            "Epoch 44/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7118 - loss: 0.5071 - val_accuracy: 0.7500 - val_loss: 0.4983\n",
            "Epoch 45/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7602 - loss: 0.4707 - val_accuracy: 0.7500 - val_loss: 0.5247\n",
            "Epoch 46/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7368 - loss: 0.4746 - val_accuracy: 0.7917 - val_loss: 0.5039\n",
            "Epoch 47/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7344 - loss: 0.4938 - val_accuracy: 0.7083 - val_loss: 0.4956\n",
            "Epoch 48/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7812 - loss: 0.4686 - val_accuracy: 0.7917 - val_loss: 0.5418\n",
            "Epoch 49/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7437 - loss: 0.5150 - val_accuracy: 0.7917 - val_loss: 0.4954\n",
            "Epoch 50/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7656 - loss: 0.4968 - val_accuracy: 0.7917 - val_loss: 0.5054\n",
            "Epoch 51/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7422 - loss: 0.4954 - val_accuracy: 0.7500 - val_loss: 0.5314\n",
            "Epoch 52/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7578 - loss: 0.4824 - val_accuracy: 0.7083 - val_loss: 0.4915\n",
            "Epoch 53/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7398 - loss: 0.4968 - val_accuracy: 0.7917 - val_loss: 0.5049\n",
            "Epoch 54/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6822 - loss: 0.4969 - val_accuracy: 0.7500 - val_loss: 0.5455\n",
            "Epoch 55/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7181 - loss: 0.5144 - val_accuracy: 0.7500 - val_loss: 0.4986\n",
            "Epoch 56/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7211 - loss: 0.5050 - val_accuracy: 0.7917 - val_loss: 0.5076\n",
            "Epoch 57/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7563 - loss: 0.4863 - val_accuracy: 0.7500 - val_loss: 0.5594\n",
            "Epoch 58/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7283 - loss: 0.4648 - val_accuracy: 0.7500 - val_loss: 0.4930\n",
            "Epoch 59/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7578 - loss: 0.4885 - val_accuracy: 0.7083 - val_loss: 0.4906\n",
            "Epoch 60/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7172 - loss: 0.4915 - val_accuracy: 0.7500 - val_loss: 0.5554\n",
            "Epoch 61/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7142 - loss: 0.5016 - val_accuracy: 0.7917 - val_loss: 0.5271\n",
            "Epoch 62/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7687 - loss: 0.4598 - val_accuracy: 0.7500 - val_loss: 0.4968\n",
            "Epoch 63/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7289 - loss: 0.4935 - val_accuracy: 0.7083 - val_loss: 0.4954\n",
            "Epoch 64/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7717 - loss: 0.4787 - val_accuracy: 0.7500 - val_loss: 0.5637\n",
            "Epoch 65/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7632 - loss: 0.4862 - val_accuracy: 0.7917 - val_loss: 0.5324\n",
            "Epoch 66/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7750 - loss: 0.4486 - val_accuracy: 0.7083 - val_loss: 0.4870\n",
            "Epoch 67/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7593 - loss: 0.4571 - val_accuracy: 0.7083 - val_loss: 0.4908\n",
            "Epoch 68/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7602 - loss: 0.4399 - val_accuracy: 0.7917 - val_loss: 0.5127\n",
            "Epoch 69/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7828 - loss: 0.4511 - val_accuracy: 0.7083 - val_loss: 0.5006\n",
            "Epoch 70/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7539 - loss: 0.4432 - val_accuracy: 0.6667 - val_loss: 0.4927\n",
            "Epoch 71/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7531 - loss: 0.4487 - val_accuracy: 0.7083 - val_loss: 0.4878\n",
            "Epoch 72/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7882 - loss: 0.4088 - val_accuracy: 0.7083 - val_loss: 0.5007\n",
            "Epoch 73/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7390 - loss: 0.4868 - val_accuracy: 0.7500 - val_loss: 0.5058\n",
            "Epoch 74/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7750 - loss: 0.4340 - val_accuracy: 0.7083 - val_loss: 0.4824\n",
            "Epoch 75/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8225 - loss: 0.4186 - val_accuracy: 0.7917 - val_loss: 0.5326\n",
            "Epoch 76/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7452 - loss: 0.4703 - val_accuracy: 0.6667 - val_loss: 0.4859\n",
            "Epoch 77/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8108 - loss: 0.4311 - val_accuracy: 0.7500 - val_loss: 0.5060\n",
            "Epoch 78/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7663 - loss: 0.4385 - val_accuracy: 0.6667 - val_loss: 0.4926\n",
            "Epoch 79/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8280 - loss: 0.4147 - val_accuracy: 0.6667 - val_loss: 0.4943\n",
            "Epoch 80/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8349 - loss: 0.4209 - val_accuracy: 0.6667 - val_loss: 0.4922\n",
            "Epoch 81/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8482 - loss: 0.4021 - val_accuracy: 0.7500 - val_loss: 0.5086\n",
            "Epoch 82/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8147 - loss: 0.4205 - val_accuracy: 0.6667 - val_loss: 0.4913\n",
            "Epoch 83/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8388 - loss: 0.4049 - val_accuracy: 0.7500 - val_loss: 0.5331\n",
            "Epoch 84/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7796 - loss: 0.4376 - val_accuracy: 0.7083 - val_loss: 0.4907\n",
            "Epoch 85/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8139 - loss: 0.4354 - val_accuracy: 0.6667 - val_loss: 0.4977\n",
            "Epoch 86/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8084 - loss: 0.4217 - val_accuracy: 0.6667 - val_loss: 0.4978\n",
            "Epoch 87/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8178 - loss: 0.3953 - val_accuracy: 0.6667 - val_loss: 0.4952\n",
            "Epoch 88/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8256 - loss: 0.4066 - val_accuracy: 0.6667 - val_loss: 0.5029\n",
            "Epoch 89/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7663 - loss: 0.4352 - val_accuracy: 0.6667 - val_loss: 0.5059\n",
            "Epoch 90/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8295 - loss: 0.4081 - val_accuracy: 0.6667 - val_loss: 0.5088\n",
            "Epoch 91/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7891 - loss: 0.4418 - val_accuracy: 0.7500 - val_loss: 0.4984\n",
            "Epoch 92/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7352 - loss: 0.4491 - val_accuracy: 0.7500 - val_loss: 0.5824\n",
            "Epoch 93/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7181 - loss: 0.4285 - val_accuracy: 0.7500 - val_loss: 0.5223\n",
            "Epoch 94/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8013 - loss: 0.4242 - val_accuracy: 0.7500 - val_loss: 0.5771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "# Model 1 predictions\n",
        "y_pred_model_3 = model_3.predict(X_test)  # Assuming 'model_1' is the trained model\n",
        "y_pred_model_3 = (y_pred_model_3 > 0.5)  # If binary classification, otherwise use softmax for multi-class\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_correct, y_pred_model_3)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test_correct, y_pred_model_3)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_test_correct, y_pred_model_3)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test_correct, y_pred_model_3)\n",
        "\n",
        "print(f\"Model CNN with Attention Evaluation:\\n\"\n",
        "      f\"Accuracy: {accuracy}\\n\"\n",
        "      f\"Precision: {precision}\\n\"\n",
        "      f\"Recall: {recall}\\n\"\n",
        "      f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VJj6SYtVvDq",
        "outputId": "279a3cb8-9d87-4d59-cc7b-5f1e2f84ff72"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
            "Model CNN with Attention Evaluation:\n",
            "Accuracy: 0.7083333333333334\n",
            "Precision: 0.625\n",
            "Recall: 0.5555555555555556\n",
            "F1 Score: 0.5882352941176471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Updated build model function\n",
        "def build_cnn_with_attention_error_classification():\n",
        "    inputs = layers.Input(shape=(88, 1))\n",
        "    x = layers.Conv1D(32, kernel_size=3, activation='relu')(inputs)\n",
        "    x = layers.Conv1D(64, kernel_size=3, activation='relu')(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "    attention = layers.Attention()([x, x])  # Self-attention\n",
        "    x = layers.Flatten()(attention)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    outputs = layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Filter only incorrect samples for training Model 2\n",
        "X_train_incorrect = X_train[y_train_correct == 0]\n",
        "X_test_incorrect = X_test[y_test_correct == 0]\n",
        "y_train_error_incorrect = y_train_error[y_train_correct == 0]\n",
        "y_test_error_incorrect = y_test_error[y_test_correct == 0]\n",
        "\n",
        "# Check and reshape if necessary\n",
        "print(f\"Shape of y_train_error_incorrect before one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect before one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Only apply one-hot encoding if they are not already encoded\n",
        "if len(y_train_error_incorrect.shape) == 1:\n",
        "    y_train_error_incorrect = to_categorical(y_train_error_incorrect, num_classes=3)\n",
        "    y_test_error_incorrect = to_categorical(y_test_error_incorrect, num_classes=3)\n",
        "\n",
        "# Check shapes after one-hot encoding\n",
        "print(f\"Shape of y_train_error_incorrect after one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect after one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Train the model\n",
        "model_4 = build_cnn_error_classification()\n",
        "\n",
        "history_4 = model_4.fit(\n",
        "    X_train_incorrect, y_train_error_incorrect,\n",
        "    validation_data=(X_test_incorrect, y_test_error_incorrect),\n",
        "    epochs=50, batch_size=32\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model_4.save('/content/cnn-with-attention_error-label.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mUSDn0MPksq",
        "outputId": "047387ce-2547-4057-e871-c1785a70307f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train_error_incorrect before one-hot encoding: (59, 3)\n",
            "Shape of y_test_error_incorrect before one-hot encoding: (15, 3)\n",
            "Shape of y_train_error_incorrect after one-hot encoding: (59, 3)\n",
            "Shape of y_test_error_incorrect after one-hot encoding: (15, 3)\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - accuracy: 0.3076 - loss: 1.0646 - val_accuracy: 0.6000 - val_loss: 0.7791\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6255 - loss: 0.7594 - val_accuracy: 0.6000 - val_loss: 0.6821\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4944 - loss: 0.7040 - val_accuracy: 0.6667 - val_loss: 0.6635\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7029 - loss: 0.6717 - val_accuracy: 0.4000 - val_loss: 0.6939\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5178 - loss: 0.6640 - val_accuracy: 0.6000 - val_loss: 0.6648\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6785 - loss: 0.6193 - val_accuracy: 0.7333 - val_loss: 0.6382\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6803 - loss: 0.6026 - val_accuracy: 0.8000 - val_loss: 0.6109\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7037 - loss: 0.5925 - val_accuracy: 0.7333 - val_loss: 0.6023\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6933 - loss: 0.5811 - val_accuracy: 0.7333 - val_loss: 0.5863\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7698 - loss: 0.5464 - val_accuracy: 0.7333 - val_loss: 0.5542\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8453 - loss: 0.5240 - val_accuracy: 0.7333 - val_loss: 0.5544\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7915 - loss: 0.4993 - val_accuracy: 0.6667 - val_loss: 0.6293\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7802 - loss: 0.4871 - val_accuracy: 0.7333 - val_loss: 0.5232\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8254 - loss: 0.4588 - val_accuracy: 0.8667 - val_loss: 0.4953\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8462 - loss: 0.4464 - val_accuracy: 0.7333 - val_loss: 0.5000\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9114 - loss: 0.4104 - val_accuracy: 0.7333 - val_loss: 0.5193\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9018 - loss: 0.3792 - val_accuracy: 0.8000 - val_loss: 0.4549\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9236 - loss: 0.3589 - val_accuracy: 0.7333 - val_loss: 0.4465\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9566 - loss: 0.3379 - val_accuracy: 0.7333 - val_loss: 0.4611\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9566 - loss: 0.3136 - val_accuracy: 0.8000 - val_loss: 0.4148\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9783 - loss: 0.2797 - val_accuracy: 0.8000 - val_loss: 0.3941\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9783 - loss: 0.2521 - val_accuracy: 0.7333 - val_loss: 0.3765\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.2272 - val_accuracy: 0.8000 - val_loss: 0.3480\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9783 - loss: 0.2066 - val_accuracy: 0.8667 - val_loss: 0.3389\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.1755 - val_accuracy: 0.8000 - val_loss: 0.3211\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9783 - loss: 0.1668 - val_accuracy: 0.8667 - val_loss: 0.3095\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.1508 - val_accuracy: 0.8667 - val_loss: 0.3055\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.1217 - val_accuracy: 0.8667 - val_loss: 0.2757\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9887 - loss: 0.1130 - val_accuracy: 0.8667 - val_loss: 0.2571\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0925 - val_accuracy: 0.8667 - val_loss: 0.2648\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0980 - val_accuracy: 0.8667 - val_loss: 0.2334\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0789 - val_accuracy: 0.9333 - val_loss: 0.2247\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0760 - val_accuracy: 0.8667 - val_loss: 0.2128\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0614 - val_accuracy: 0.8667 - val_loss: 0.2013\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0525 - val_accuracy: 0.9333 - val_loss: 0.1896\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0492 - val_accuracy: 0.8667 - val_loss: 0.1839\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0407 - val_accuracy: 0.8667 - val_loss: 0.1750\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0349 - val_accuracy: 0.9333 - val_loss: 0.1795\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0351 - val_accuracy: 0.9333 - val_loss: 0.1607\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0352 - val_accuracy: 0.9333 - val_loss: 0.1621\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 0.9333 - val_loss: 0.1677\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0272 - val_accuracy: 0.9333 - val_loss: 0.1615\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0212 - val_accuracy: 0.9333 - val_loss: 0.1507\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 0.9333 - val_loss: 0.1534\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0226 - val_accuracy: 0.9333 - val_loss: 0.1553\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.9333 - val_loss: 0.1503\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9333 - val_loss: 0.1334\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9333 - val_loss: 0.1349\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9333 - val_loss: 0.1338\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.9333 - val_loss: 0.1499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convert true labels to class indices if they are one-hot encoded\n",
        "y_test_error_incorrect_class = np.argmax(y_test_error_incorrect, axis=1)\n",
        "\n",
        "# Model 2 predictions (assuming the model outputs class probabilities)\n",
        "y_pred_model_4 = model_4.predict(X_test_incorrect)  # Your model's predictions\n",
        "y_pred_model_4 = np.argmax(y_pred_model_4, axis=1)  # Convert predictions to class indices\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_error_incorrect_class, y_pred_model_4)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'],\n",
        "            yticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'])\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# F1-score for each error type (class)\n",
        "f1_error_1 = f1_score(y_test_error_incorrect_class, y_pred_model_4, labels=[0], average='micro')  # Error Type 1\n",
        "f1_error_2 = f1_score(y_test_error_incorrect_class, y_pred_model_4, labels=[1], average='micro')  # Error Type 2\n",
        "f1_error_3 = f1_score(y_test_error_incorrect_class, y_pred_model_4, labels=[2], average='micro')  # Error Type 3\n",
        "\n",
        "print(f\"Model CNN with Attention Evaluation:\\n\"\n",
        "      f\"F1 Score for Error Type 1: {f1_error_1}\\n\"\n",
        "      f\"F1 Score for Error Type 2: {f1_error_2}\\n\"\n",
        "      f\"F1 Score for Error Type 3: {f1_error_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "VVpXb3-OYIx6",
        "outputId": "4542abcd-1043-4c43-f1ad-17dec71a216d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e3f25ebc3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model CNN with Attention Evaluation:\n",
            "F1 Score for Error Type 1: 0.0\n",
            "F1 Score for Error Type 2: 0.9473684210526315\n",
            "F1 Score for Error Type 3: 0.9090909090909091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG"
      ],
      "metadata": {
        "id": "meDXOTfRQc93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_vgg_correct_incorrect():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(88, 1)),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Step 1: Build the model\n",
        "model_5 = build_vgg_correct_incorrect()\n",
        "\n",
        "# Step 3: Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "history_5 = model_5.fit(\n",
        "    X_train, y_train_correct,\n",
        "    validation_data=(X_test, y_test_correct),\n",
        "    epochs=1000, batch_size=32, callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "model_5.save('/content/vgg_pose-label.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_ijHTtQQfdz",
        "outputId": "5b0ccf50-5daa-4b0c-8119-ac7b54272eb9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - accuracy: 0.6527 - loss: 0.6808 - val_accuracy: 0.6250 - val_loss: 0.6624\n",
            "Epoch 2/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6449 - loss: 0.6381 - val_accuracy: 0.6250 - val_loss: 0.6397\n",
            "Epoch 3/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6761 - loss: 0.6123 - val_accuracy: 0.6250 - val_loss: 0.6173\n",
            "Epoch 4/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6253 - loss: 0.6116 - val_accuracy: 0.6250 - val_loss: 0.5836\n",
            "Epoch 5/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6722 - loss: 0.5523 - val_accuracy: 0.6667 - val_loss: 0.5512\n",
            "Epoch 6/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7882 - loss: 0.5211 - val_accuracy: 0.7083 - val_loss: 0.5198\n",
            "Epoch 7/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6720 - loss: 0.5236 - val_accuracy: 0.7083 - val_loss: 0.5165\n",
            "Epoch 8/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7048 - loss: 0.4938 - val_accuracy: 0.7083 - val_loss: 0.5210\n",
            "Epoch 9/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7741 - loss: 0.4203 - val_accuracy: 0.7083 - val_loss: 0.4942\n",
            "Epoch 10/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7709 - loss: 0.4523 - val_accuracy: 0.7083 - val_loss: 0.5508\n",
            "Epoch 11/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8084 - loss: 0.3706 - val_accuracy: 0.7083 - val_loss: 0.5372\n",
            "Epoch 12/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7437 - loss: 0.3954 - val_accuracy: 0.7083 - val_loss: 0.6193\n",
            "Epoch 13/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8256 - loss: 0.3793 - val_accuracy: 0.7083 - val_loss: 0.5685\n",
            "Epoch 14/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8505 - loss: 0.3035 - val_accuracy: 0.7083 - val_loss: 0.5983\n",
            "Epoch 15/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8303 - loss: 0.3068 - val_accuracy: 0.7917 - val_loss: 0.6396\n",
            "Epoch 16/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7546 - loss: 0.4507 - val_accuracy: 0.7083 - val_loss: 0.6000\n",
            "Epoch 17/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8536 - loss: 0.3273 - val_accuracy: 0.7083 - val_loss: 0.6609\n",
            "Epoch 18/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8979 - loss: 0.3041 - val_accuracy: 0.7500 - val_loss: 0.5895\n",
            "Epoch 19/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8334 - loss: 0.3241 - val_accuracy: 0.7500 - val_loss: 0.6047\n",
            "Epoch 20/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8349 - loss: 0.3099 - val_accuracy: 0.7083 - val_loss: 0.6971\n",
            "Epoch 21/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7880 - loss: 0.3232 - val_accuracy: 0.7500 - val_loss: 0.6395\n",
            "Epoch 22/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8801 - loss: 0.2477 - val_accuracy: 0.7500 - val_loss: 0.6545\n",
            "Epoch 23/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8916 - loss: 0.2799 - val_accuracy: 0.6667 - val_loss: 0.6791\n",
            "Epoch 24/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9307 - loss: 0.2279 - val_accuracy: 0.6667 - val_loss: 0.6898\n",
            "Epoch 25/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9479 - loss: 0.2038 - val_accuracy: 0.7083 - val_loss: 0.6968\n",
            "Epoch 26/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9416 - loss: 0.2095 - val_accuracy: 0.6667 - val_loss: 0.7284\n",
            "Epoch 27/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9346 - loss: 0.1946 - val_accuracy: 0.6667 - val_loss: 0.7445\n",
            "Epoch 28/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9603 - loss: 0.1853 - val_accuracy: 0.7500 - val_loss: 0.7554\n",
            "Epoch 29/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9470 - loss: 0.1848 - val_accuracy: 0.7083 - val_loss: 0.7946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "# Model 1 predictions\n",
        "y_pred_model_5 = model_5.predict(X_test)  # Assuming 'model_1' is the trained model\n",
        "y_pred_model_5 = (y_pred_model_5 > 0.5)  # If binary classification, otherwise use softmax for multi-class\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_correct, y_pred_model_5)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test_correct, y_pred_model_5)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_test_correct, y_pred_model_5)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test_correct, y_pred_model_5)\n",
        "\n",
        "print(f\"Model VGG Evaluation:\\n\"\n",
        "      f\"Accuracy: {accuracy}\\n\"\n",
        "      f\"Precision: {precision}\\n\"\n",
        "      f\"Recall: {recall}\\n\"\n",
        "      f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68mow8dNV-x2",
        "outputId": "aa3423b2-a678-43c4-a6c2-d065f5d7e906"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
            "Model VGG Evaluation:\n",
            "Accuracy: 0.7083333333333334\n",
            "Precision: 0.6\n",
            "Recall: 0.6666666666666666\n",
            "F1 Score: 0.631578947368421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Updated build model function\n",
        "def build_vgg_error_classification():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(88, 1)),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Filter only incorrect samples for training Model 2\n",
        "X_train_incorrect = X_train[y_train_correct == 0]\n",
        "X_test_incorrect = X_test[y_test_correct == 0]\n",
        "y_train_error_incorrect = y_train_error[y_train_correct == 0]\n",
        "y_test_error_incorrect = y_test_error[y_test_correct == 0]\n",
        "\n",
        "# Check and reshape if necessary\n",
        "print(f\"Shape of y_train_error_incorrect before one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect before one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Only apply one-hot encoding if they are not already encoded\n",
        "if len(y_train_error_incorrect.shape) == 1:\n",
        "    y_train_error_incorrect = to_categorical(y_train_error_incorrect, num_classes=3)\n",
        "    y_test_error_incorrect = to_categorical(y_test_error_incorrect, num_classes=3)\n",
        "\n",
        "# Check shapes after one-hot encoding\n",
        "print(f\"Shape of y_train_error_incorrect after one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect after one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Train the model\n",
        "model_6 = build_vgg_error_classification()\n",
        "\n",
        "history_6 = model_6.fit(\n",
        "    X_train_incorrect, y_train_error_incorrect,\n",
        "    validation_data=(X_test_incorrect, y_test_error_incorrect),\n",
        "    epochs=50, batch_size=32\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model_6.save('/content/vgg_error-label.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMa14zzJR-vV",
        "outputId": "358beaa2-f4e7-47e0-d8c0-b1d71783139b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train_error_incorrect before one-hot encoding: (59, 3)\n",
            "Shape of y_test_error_incorrect before one-hot encoding: (15, 3)\n",
            "Shape of y_train_error_incorrect after one-hot encoding: (59, 3)\n",
            "Shape of y_test_error_incorrect after one-hot encoding: (15, 3)\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 281ms/step - accuracy: 0.2007 - loss: 1.0627 - val_accuracy: 0.4000 - val_loss: 0.8711\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5187 - loss: 0.8275 - val_accuracy: 0.4000 - val_loss: 0.7232\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5056 - loss: 0.6962 - val_accuracy: 0.6000 - val_loss: 0.6664\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6133 - loss: 0.6852 - val_accuracy: 0.4000 - val_loss: 0.7417\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5056 - loss: 0.6784 - val_accuracy: 0.6667 - val_loss: 0.6641\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5595 - loss: 0.6621 - val_accuracy: 0.6667 - val_loss: 0.6321\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6889 - loss: 0.6669 - val_accuracy: 0.4000 - val_loss: 0.7328\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6142 - loss: 0.6062 - val_accuracy: 0.6000 - val_loss: 0.6037\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5717 - loss: 0.6416 - val_accuracy: 0.6667 - val_loss: 0.5906\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7142 - loss: 0.5955 - val_accuracy: 0.4667 - val_loss: 0.6761\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7029 - loss: 0.5741 - val_accuracy: 0.6667 - val_loss: 0.6183\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7585 - loss: 0.5245 - val_accuracy: 0.8000 - val_loss: 0.5355\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7811 - loss: 0.5386 - val_accuracy: 0.8000 - val_loss: 0.5325\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8245 - loss: 0.4761 - val_accuracy: 0.8000 - val_loss: 0.5359\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8349 - loss: 0.4249 - val_accuracy: 0.8000 - val_loss: 0.4880\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8784 - loss: 0.3688 - val_accuracy: 0.7333 - val_loss: 0.4566\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8575 - loss: 0.3510 - val_accuracy: 0.7333 - val_loss: 0.4561\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9557 - loss: 0.2754 - val_accuracy: 0.8000 - val_loss: 0.4051\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9123 - loss: 0.2516 - val_accuracy: 0.7333 - val_loss: 0.4075\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9670 - loss: 0.1995 - val_accuracy: 0.8000 - val_loss: 0.3646\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9661 - loss: 0.1786 - val_accuracy: 0.7333 - val_loss: 0.3515\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9557 - loss: 0.1494 - val_accuracy: 0.7333 - val_loss: 0.4003\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9783 - loss: 0.1076 - val_accuracy: 0.8667 - val_loss: 0.2977\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9340 - loss: 0.1148 - val_accuracy: 0.8000 - val_loss: 0.3366\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9661 - loss: 0.1147 - val_accuracy: 0.8667 - val_loss: 0.2634\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0705 - val_accuracy: 0.8667 - val_loss: 0.3021\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9349 - loss: 0.1286 - val_accuracy: 0.8000 - val_loss: 0.2882\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0529 - val_accuracy: 0.8000 - val_loss: 0.3555\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0457 - val_accuracy: 0.9333 - val_loss: 0.1760\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 0.8667 - val_loss: 0.2072\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0328 - val_accuracy: 0.8667 - val_loss: 0.2275\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 0.9333 - val_loss: 0.2465\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0164 - val_accuracy: 0.9333 - val_loss: 0.2514\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 0.9333 - val_loss: 0.1849\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.9333 - val_loss: 0.1178\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9333 - val_loss: 0.0923\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9333 - val_loss: 0.0866\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9333 - val_loss: 0.1138\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9333 - val_loss: 0.1417\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9333 - val_loss: 0.1550\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9333 - val_loss: 0.1417\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.1235\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9333 - val_loss: 0.1160\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9333 - val_loss: 0.1096\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9333 - val_loss: 0.1087\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9333 - val_loss: 0.1051\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.0974\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 9.8835e-04 - val_accuracy: 0.9333 - val_loss: 0.0874\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 9.9777e-04 - val_accuracy: 0.9333 - val_loss: 0.0755\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 8.7735e-04 - val_accuracy: 0.9333 - val_loss: 0.0686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convert true labels to class indices if they are one-hot encoded\n",
        "y_test_error_incorrect_class = np.argmax(y_test_error_incorrect, axis=1)\n",
        "\n",
        "# Model 2 predictions (assuming the model outputs class probabilities)\n",
        "y_pred_model_6 = model_6.predict(X_test_incorrect)  # Your model's predictions\n",
        "y_pred_model_6 = np.argmax(y_pred_model_6, axis=1)  # Convert predictions to class indices\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_error_incorrect_class, y_pred_model_6)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'],\n",
        "            yticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'])\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# F1-score for each error type (class)\n",
        "f1_error_1 = f1_score(y_test_error_incorrect_class, y_pred_model_6, labels=[0], average='micro')  # Error Type 1\n",
        "f1_error_2 = f1_score(y_test_error_incorrect_class, y_pred_model_6, labels=[1], average='micro')  # Error Type 2\n",
        "f1_error_3 = f1_score(y_test_error_incorrect_class, y_pred_model_6, labels=[2], average='micro')  # Error Type 3\n",
        "\n",
        "print(f\"Model VGG Evaluation:\\n\"\n",
        "      f\"F1 Score for Error Type 1: {f1_error_1}\\n\"\n",
        "      f\"F1 Score for Error Type 2: {f1_error_2}\\n\"\n",
        "      f\"F1 Score for Error Type 3: {f1_error_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "m9bh8y0jZDDd",
        "outputId": "bb46bd54-c535-4037-be4e-e2cdeec0259f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model VGG Evaluation:\n",
            "F1 Score for Error Type 1: 0.0\n",
            "F1 Score for Error Type 2: 0.9411764705882353\n",
            "F1 Score for Error Type 3: 0.9230769230769231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer"
      ],
      "metadata": {
        "id": "QdfhV0YdTRxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def build_transformer_correct_incorrect():\n",
        "    inputs = layers.Input(shape=(88, 1))\n",
        "\n",
        "    # Pass through a dense layer before the attention layer\n",
        "    x = layers.Dense(64, activation='relu')(inputs)\n",
        "\n",
        "    # Add Multi-Head Attention layer\n",
        "    attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
        "\n",
        "    # Add a residual connection and layer normalization\n",
        "    x = layers.Add()([x, attention_output])\n",
        "    x = layers.LayerNormalization()(x)\n",
        "\n",
        "    # Apply Global Average Pooling\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Dense layers\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Define and compile the model\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Step 1: Build the model\n",
        "model_7 = build_transformer_correct_incorrect()\n",
        "\n",
        "# Step 2: Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "# Step 3: Train the model\n",
        "history_7 = model_7.fit(\n",
        "    X_train, y_train_correct,\n",
        "    validation_data=(X_test, y_test_correct),\n",
        "    epochs=1000, batch_size=32, callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model_7.save('/content/transformer_pose-label.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sICI-wk1TS_G",
        "outputId": "40d092e9-c449-4b5d-960d-744b59c0334d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 333ms/step - accuracy: 0.4586 - loss: 0.7343 - val_accuracy: 0.6250 - val_loss: 0.7101\n",
            "Epoch 2/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6175 - loss: 0.7138 - val_accuracy: 0.6250 - val_loss: 0.6597\n",
            "Epoch 3/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6292 - loss: 0.6646 - val_accuracy: 0.6250 - val_loss: 0.6607\n",
            "Epoch 4/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6878 - loss: 0.6473 - val_accuracy: 0.6250 - val_loss: 0.6597\n",
            "Epoch 5/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6371 - loss: 0.6553 - val_accuracy: 0.6250 - val_loss: 0.6534\n",
            "Epoch 6/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6253 - loss: 0.6543 - val_accuracy: 0.6250 - val_loss: 0.6497\n",
            "Epoch 7/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6371 - loss: 0.6463 - val_accuracy: 0.6250 - val_loss: 0.6478\n",
            "Epoch 8/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6253 - loss: 0.6521 - val_accuracy: 0.6250 - val_loss: 0.6455\n",
            "Epoch 9/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6527 - loss: 0.6326 - val_accuracy: 0.6250 - val_loss: 0.6449\n",
            "Epoch 10/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6410 - loss: 0.6439 - val_accuracy: 0.6250 - val_loss: 0.6401\n",
            "Epoch 11/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6292 - loss: 0.6412 - val_accuracy: 0.6250 - val_loss: 0.6366\n",
            "Epoch 12/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6371 - loss: 0.6348 - val_accuracy: 0.6250 - val_loss: 0.6360\n",
            "Epoch 13/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6292 - loss: 0.6347 - val_accuracy: 0.6250 - val_loss: 0.6342\n",
            "Epoch 14/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6566 - loss: 0.6165 - val_accuracy: 0.6250 - val_loss: 0.6283\n",
            "Epoch 15/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6175 - loss: 0.6415 - val_accuracy: 0.6667 - val_loss: 0.6246\n",
            "Epoch 16/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6644 - loss: 0.6238 - val_accuracy: 0.6250 - val_loss: 0.6270\n",
            "Epoch 17/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6488 - loss: 0.6164 - val_accuracy: 0.6250 - val_loss: 0.6198\n",
            "Epoch 18/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6488 - loss: 0.6175 - val_accuracy: 0.6667 - val_loss: 0.6138\n",
            "Epoch 19/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6566 - loss: 0.6080 - val_accuracy: 0.6250 - val_loss: 0.6104\n",
            "Epoch 20/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6449 - loss: 0.6051 - val_accuracy: 0.6250 - val_loss: 0.6092\n",
            "Epoch 21/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6277 - loss: 0.6079 - val_accuracy: 0.6667 - val_loss: 0.6019\n",
            "Epoch 22/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6449 - loss: 0.6062 - val_accuracy: 0.6250 - val_loss: 0.6039\n",
            "Epoch 23/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5771 - loss: 0.6162 - val_accuracy: 0.7083 - val_loss: 0.5934\n",
            "Epoch 24/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6316 - loss: 0.6005 - val_accuracy: 0.6667 - val_loss: 0.6020\n",
            "Epoch 25/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6316 - loss: 0.5978 - val_accuracy: 0.7083 - val_loss: 0.5862\n",
            "Epoch 26/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5934 - loss: 0.6166 - val_accuracy: 0.7083 - val_loss: 0.5820\n",
            "Epoch 27/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6106 - loss: 0.6203 - val_accuracy: 0.6667 - val_loss: 0.5988\n",
            "Epoch 28/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6151 - loss: 0.6477 - val_accuracy: 0.7917 - val_loss: 0.5792\n",
            "Epoch 29/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6590 - loss: 0.5869 - val_accuracy: 0.6667 - val_loss: 0.5888\n",
            "Epoch 30/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6286 - loss: 0.6030 - val_accuracy: 0.7917 - val_loss: 0.5753\n",
            "Epoch 31/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6535 - loss: 0.5935 - val_accuracy: 0.7083 - val_loss: 0.5759\n",
            "Epoch 32/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6208 - loss: 0.5897 - val_accuracy: 0.7083 - val_loss: 0.5743\n",
            "Epoch 33/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6770 - loss: 0.5640 - val_accuracy: 0.7917 - val_loss: 0.5693\n",
            "Epoch 34/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6308 - loss: 0.6217 - val_accuracy: 0.7917 - val_loss: 0.5674\n",
            "Epoch 35/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5771 - loss: 0.5859 - val_accuracy: 0.6667 - val_loss: 0.6003\n",
            "Epoch 36/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6410 - loss: 0.6074 - val_accuracy: 0.7917 - val_loss: 0.5664\n",
            "Epoch 37/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5442 - loss: 0.6528 - val_accuracy: 0.7917 - val_loss: 0.5689\n",
            "Epoch 38/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.6659 - loss: 0.5910 - val_accuracy: 0.6667 - val_loss: 0.5955\n",
            "Epoch 39/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.6644 - loss: 0.5785 - val_accuracy: 0.7917 - val_loss: 0.5678\n",
            "Epoch 40/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.6464 - loss: 0.6182 - val_accuracy: 0.7917 - val_loss: 0.5718\n",
            "Epoch 41/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6644 - loss: 0.5923 - val_accuracy: 0.6667 - val_loss: 0.5983\n",
            "Epoch 42/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.6371 - loss: 0.6050 - val_accuracy: 0.6667 - val_loss: 0.5756\n",
            "Epoch 43/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6403 - loss: 0.5804 - val_accuracy: 0.7917 - val_loss: 0.5656\n",
            "Epoch 44/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6371 - loss: 0.6088 - val_accuracy: 0.7083 - val_loss: 0.5688\n",
            "Epoch 45/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6542 - loss: 0.5908 - val_accuracy: 0.6667 - val_loss: 0.5808\n",
            "Epoch 46/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6512 - loss: 0.5839 - val_accuracy: 0.7083 - val_loss: 0.5711\n",
            "Epoch 47/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6440 - loss: 0.5945 - val_accuracy: 0.7500 - val_loss: 0.5707\n",
            "Epoch 48/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5934 - loss: 0.6194 - val_accuracy: 0.6667 - val_loss: 0.5733\n",
            "Epoch 49/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5973 - loss: 0.5916 - val_accuracy: 0.6667 - val_loss: 0.5746\n",
            "Epoch 50/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6090 - loss: 0.5908 - val_accuracy: 0.7083 - val_loss: 0.5669\n",
            "Epoch 51/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6542 - loss: 0.5756 - val_accuracy: 0.7917 - val_loss: 0.5630\n",
            "Epoch 52/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5864 - loss: 0.6055 - val_accuracy: 0.6667 - val_loss: 0.5745\n",
            "Epoch 53/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6479 - loss: 0.5965 - val_accuracy: 0.7917 - val_loss: 0.5598\n",
            "Epoch 54/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6386 - loss: 0.6045 - val_accuracy: 0.7917 - val_loss: 0.5641\n",
            "Epoch 55/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6449 - loss: 0.5856 - val_accuracy: 0.7083 - val_loss: 0.5745\n",
            "Epoch 56/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6581 - loss: 0.5896 - val_accuracy: 0.7917 - val_loss: 0.5580\n",
            "Epoch 57/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6347 - loss: 0.5971 - val_accuracy: 0.7917 - val_loss: 0.5578\n",
            "Epoch 58/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6596 - loss: 0.5797 - val_accuracy: 0.6667 - val_loss: 0.5772\n",
            "Epoch 59/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6145 - loss: 0.5845 - val_accuracy: 0.6667 - val_loss: 0.5796\n",
            "Epoch 60/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6824 - loss: 0.5544 - val_accuracy: 0.7917 - val_loss: 0.5571\n",
            "Epoch 61/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6332 - loss: 0.5965 - val_accuracy: 0.7083 - val_loss: 0.5600\n",
            "Epoch 62/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5943 - loss: 0.5903 - val_accuracy: 0.6667 - val_loss: 0.5750\n",
            "Epoch 63/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6472 - loss: 0.5693 - val_accuracy: 0.7083 - val_loss: 0.5669\n",
            "Epoch 64/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6729 - loss: 0.5809 - val_accuracy: 0.7917 - val_loss: 0.5569\n",
            "Epoch 65/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6722 - loss: 0.5791 - val_accuracy: 0.7917 - val_loss: 0.5589\n",
            "Epoch 66/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6573 - loss: 0.6106 - val_accuracy: 0.7083 - val_loss: 0.5688\n",
            "Epoch 67/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6503 - loss: 0.5976 - val_accuracy: 0.7083 - val_loss: 0.5720\n",
            "Epoch 68/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5941 - loss: 0.6373 - val_accuracy: 0.7917 - val_loss: 0.5541\n",
            "Epoch 69/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6238 - loss: 0.5936 - val_accuracy: 0.6667 - val_loss: 0.5845\n",
            "Epoch 70/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6355 - loss: 0.5759 - val_accuracy: 0.7917 - val_loss: 0.5613\n",
            "Epoch 71/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6238 - loss: 0.6017 - val_accuracy: 0.7917 - val_loss: 0.5554\n",
            "Epoch 72/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5786 - loss: 0.6126 - val_accuracy: 0.6667 - val_loss: 0.5789\n",
            "Epoch 73/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6542 - loss: 0.5769 - val_accuracy: 0.7917 - val_loss: 0.5621\n",
            "Epoch 74/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6761 - loss: 0.5486 - val_accuracy: 0.7917 - val_loss: 0.5563\n",
            "Epoch 75/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6214 - loss: 0.5899 - val_accuracy: 0.7917 - val_loss: 0.5557\n",
            "Epoch 76/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6729 - loss: 0.5787 - val_accuracy: 0.7083 - val_loss: 0.5673\n",
            "Epoch 77/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6277 - loss: 0.5664 - val_accuracy: 0.7083 - val_loss: 0.5687\n",
            "Epoch 78/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6168 - loss: 0.5540 - val_accuracy: 0.7917 - val_loss: 0.5570\n",
            "Epoch 79/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6636 - loss: 0.5808 - val_accuracy: 0.7917 - val_loss: 0.5538\n",
            "Epoch 80/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6112 - loss: 0.5949 - val_accuracy: 0.7917 - val_loss: 0.5627\n",
            "Epoch 81/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6433 - loss: 0.5802 - val_accuracy: 0.6667 - val_loss: 0.5851\n",
            "Epoch 82/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6371 - loss: 0.6238 - val_accuracy: 0.7917 - val_loss: 0.5548\n",
            "Epoch 83/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.6675 - loss: 0.5787 - val_accuracy: 0.7917 - val_loss: 0.5641\n",
            "Epoch 84/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.6199 - loss: 0.6177 - val_accuracy: 0.7083 - val_loss: 0.5693\n",
            "Epoch 85/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.6574 - loss: 0.5394 - val_accuracy: 0.7917 - val_loss: 0.5571\n",
            "Epoch 86/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.6503 - loss: 0.5796 - val_accuracy: 0.7917 - val_loss: 0.5553\n",
            "Epoch 87/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.6394 - loss: 0.5888 - val_accuracy: 0.7917 - val_loss: 0.5593\n",
            "Epoch 88/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.6838 - loss: 0.5978 - val_accuracy: 0.6667 - val_loss: 0.5868\n",
            "Epoch 89/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6199 - loss: 0.5962 - val_accuracy: 0.7083 - val_loss: 0.5681\n",
            "Epoch 90/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5841 - loss: 0.6044 - val_accuracy: 0.7500 - val_loss: 0.5573\n",
            "Epoch 91/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6316 - loss: 0.5926 - val_accuracy: 0.6667 - val_loss: 0.5722\n",
            "Epoch 92/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6199 - loss: 0.6005 - val_accuracy: 0.7083 - val_loss: 0.5742\n",
            "Epoch 93/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6792 - loss: 0.5769 - val_accuracy: 0.7917 - val_loss: 0.5562\n",
            "Epoch 94/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6464 - loss: 0.5672 - val_accuracy: 0.7917 - val_loss: 0.5562\n",
            "Epoch 95/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6464 - loss: 0.5748 - val_accuracy: 0.7917 - val_loss: 0.5628\n",
            "Epoch 96/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6675 - loss: 0.5782 - val_accuracy: 0.7917 - val_loss: 0.5576\n",
            "Epoch 97/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6675 - loss: 0.5636 - val_accuracy: 0.7917 - val_loss: 0.5546\n",
            "Epoch 98/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6816 - loss: 0.5674 - val_accuracy: 0.7917 - val_loss: 0.5619\n",
            "Epoch 99/1000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6987 - loss: 0.5482 - val_accuracy: 0.7917 - val_loss: 0.5581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "# Model 1 predictions\n",
        "y_pred_model_7 = model_7.predict(X_test)  # Assuming 'model_1' is the trained model\n",
        "y_pred_model_7 = (y_pred_model_7 > 0.5)  # If binary classification, otherwise use softmax for multi-class\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_correct, y_pred_model_7)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test_correct, y_pred_model_7)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_test_correct, y_pred_model_7)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test_correct, y_pred_model_7)\n",
        "\n",
        "print(f\"Model Transformer Evaluation:\\n\"\n",
        "      f\"Accuracy: {accuracy}\\n\"\n",
        "      f\"Precision: {precision}\\n\"\n",
        "      f\"Recall: {recall}\\n\"\n",
        "      f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu6oN2u0WHyY",
        "outputId": "df38701a-672e-47ff-e4c8-d68768c53c70"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
            "Model Transformer Evaluation:\n",
            "Accuracy: 0.7916666666666666\n",
            "Precision: 1.0\n",
            "Recall: 0.4444444444444444\n",
            "F1 Score: 0.6153846153846154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def build_transformer_error_classification():\n",
        "    inputs = layers.Input(shape=(88, 1))\n",
        "\n",
        "    # Pass through a dense layer before the attention layer\n",
        "    x = layers.Dense(64, activation='relu')(inputs)\n",
        "\n",
        "    # Add Multi-Head Attention layer\n",
        "    attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
        "\n",
        "    # Add a residual connection and layer normalization\n",
        "    x = layers.Add()([x, attention_output])\n",
        "    x = layers.LayerNormalization()(x)\n",
        "\n",
        "    # Apply Global Average Pooling\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Dense layers\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    outputs = layers.Dense(3, activation='softmax')(x)  # Adjust to 3 output classes\n",
        "\n",
        "    # Define and compile the model\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Filter only incorrect samples for training Model 2\n",
        "X_train_incorrect = X_train[y_train_correct == 0]\n",
        "X_test_incorrect = X_test[y_test_correct == 0]\n",
        "y_train_error_incorrect = y_train_error[y_train_correct == 0]\n",
        "y_test_error_incorrect = y_test_error[y_test_correct == 0]\n",
        "\n",
        "# Check and reshape if necessary\n",
        "print(f\"Shape of y_train_error_incorrect before one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect before one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Only apply one-hot encoding if they are not already encoded\n",
        "if len(y_train_error_incorrect.shape) == 1:\n",
        "    y_train_error_incorrect = to_categorical(y_train_error_incorrect, num_classes=3)\n",
        "    y_test_error_incorrect = to_categorical(y_test_error_incorrect, num_classes=3)\n",
        "\n",
        "# Check shapes after one-hot encoding\n",
        "print(f\"Shape of y_train_error_incorrect after one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect after one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Train the model\n",
        "model_8 = build_transformer_error_classification()\n",
        "\n",
        "history_8 = model_8.fit(\n",
        "    X_train_incorrect, y_train_error_incorrect,\n",
        "    validation_data=(X_test_incorrect, y_test_error_incorrect),\n",
        "    epochs=50, batch_size=32\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model_8.save('/content/transformer_error-label.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5UkKXc9UU5V",
        "outputId": "758c208c-b45b-43f3-a4ea-4d04fe0cd6ea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train_error_incorrect before one-hot encoding: (59, 3)\n",
            "Shape of y_test_error_incorrect before one-hot encoding: (15, 3)\n",
            "Shape of y_train_error_incorrect after one-hot encoding: (59, 3)\n",
            "Shape of y_test_error_incorrect after one-hot encoding: (15, 3)\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 484ms/step - accuracy: 0.1695 - loss: 1.2029 - val_accuracy: 0.6000 - val_loss: 0.7476\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.4839 - loss: 0.8033 - val_accuracy: 0.4000 - val_loss: 0.7383\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.5056 - loss: 0.7176 - val_accuracy: 0.4000 - val_loss: 0.7542\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5265 - loss: 0.7022 - val_accuracy: 0.6000 - val_loss: 0.6914\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.4631 - loss: 0.6974 - val_accuracy: 0.6000 - val_loss: 0.6776\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.4839 - loss: 0.7087 - val_accuracy: 0.6000 - val_loss: 0.6830\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.5152 - loss: 0.6926 - val_accuracy: 0.4000 - val_loss: 0.7078\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.4952 - loss: 0.6956 - val_accuracy: 0.4000 - val_loss: 0.7371\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5265 - loss: 0.6998 - val_accuracy: 0.4000 - val_loss: 0.7242\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.4952 - loss: 0.7042 - val_accuracy: 0.6000 - val_loss: 0.6824\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4839 - loss: 0.6986 - val_accuracy: 0.6000 - val_loss: 0.6805\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4839 - loss: 0.7002 - val_accuracy: 0.4000 - val_loss: 0.6955\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5369 - loss: 0.6993 - val_accuracy: 0.4000 - val_loss: 0.7196\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5369 - loss: 0.6932 - val_accuracy: 0.4000 - val_loss: 0.7072\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5717 - loss: 0.6903 - val_accuracy: 0.6000 - val_loss: 0.6843\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.4735 - loss: 0.6988 - val_accuracy: 0.6000 - val_loss: 0.6798\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4839 - loss: 0.6988 - val_accuracy: 0.6000 - val_loss: 0.6872\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5152 - loss: 0.6921 - val_accuracy: 0.3333 - val_loss: 0.7008\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5169 - loss: 0.6924 - val_accuracy: 0.4000 - val_loss: 0.7208\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5161 - loss: 0.6952 - val_accuracy: 0.4000 - val_loss: 0.7185\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5291 - loss: 0.7001 - val_accuracy: 0.4667 - val_loss: 0.6912\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.4283 - loss: 0.6994 - val_accuracy: 0.6000 - val_loss: 0.6838\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4274 - loss: 0.6946 - val_accuracy: 0.3333 - val_loss: 0.7032\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4961 - loss: 0.6959 - val_accuracy: 0.4000 - val_loss: 0.7092\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5690 - loss: 0.6977 - val_accuracy: 0.4000 - val_loss: 0.7224\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5404 - loss: 0.7020 - val_accuracy: 0.6000 - val_loss: 0.6879\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.4179 - loss: 0.6966 - val_accuracy: 0.6000 - val_loss: 0.6812\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4500 - loss: 0.6974 - val_accuracy: 0.3333 - val_loss: 0.6972\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5708 - loss: 0.6932 - val_accuracy: 0.4000 - val_loss: 0.7157\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5169 - loss: 0.6949 - val_accuracy: 0.4000 - val_loss: 0.7070\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5482 - loss: 0.6907 - val_accuracy: 0.4000 - val_loss: 0.6955\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5274 - loss: 0.6917 - val_accuracy: 0.6000 - val_loss: 0.6878\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4622 - loss: 0.6936 - val_accuracy: 0.6000 - val_loss: 0.6836\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5152 - loss: 0.6947 - val_accuracy: 0.6000 - val_loss: 0.6881\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5161 - loss: 0.6914 - val_accuracy: 0.4000 - val_loss: 0.7158\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5161 - loss: 0.6952 - val_accuracy: 0.4000 - val_loss: 0.7265\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5169 - loss: 0.6992 - val_accuracy: 0.3333 - val_loss: 0.6985\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4283 - loss: 0.6998 - val_accuracy: 0.6000 - val_loss: 0.6817\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4952 - loss: 0.6985 - val_accuracy: 0.6667 - val_loss: 0.6932\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4613 - loss: 0.6927 - val_accuracy: 0.4000 - val_loss: 0.7043\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.4961 - loss: 0.6941 - val_accuracy: 0.4000 - val_loss: 0.7138\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5369 - loss: 0.6964 - val_accuracy: 0.4000 - val_loss: 0.7219\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5473 - loss: 0.6877 - val_accuracy: 0.3333 - val_loss: 0.6974\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6142 - loss: 0.6915 - val_accuracy: 0.6000 - val_loss: 0.6773\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5256 - loss: 0.7022 - val_accuracy: 0.6000 - val_loss: 0.6767\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4283 - loss: 0.7092 - val_accuracy: 0.4000 - val_loss: 0.7142\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5577 - loss: 0.7077 - val_accuracy: 0.4000 - val_loss: 0.7542\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4952 - loss: 0.7101 - val_accuracy: 0.4000 - val_loss: 0.7019\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4935 - loss: 0.6975 - val_accuracy: 0.6000 - val_loss: 0.6785\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5464 - loss: 0.7021 - val_accuracy: 0.6000 - val_loss: 0.6778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convert true labels to class indices if they are one-hot encoded\n",
        "y_test_error_incorrect_class = np.argmax(y_test_error_incorrect, axis=1)\n",
        "\n",
        "# Model 2 predictions (assuming the model outputs class probabilities)\n",
        "y_pred_model_8 = model_8.predict(X_test_incorrect)  # Your model's predictions\n",
        "y_pred_model_8 = np.argmax(y_pred_model_8, axis=1)  # Convert predictions to class indices\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_error_incorrect_class, y_pred_model_8)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'],\n",
        "            yticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'])\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# F1-score for each error type (class)\n",
        "f1_error_1 = f1_score(y_test_error_incorrect_class, y_pred_model_8, labels=[0], average='micro')  # Error Type 1\n",
        "f1_error_2 = f1_score(y_test_error_incorrect_class, y_pred_model_8, labels=[1], average='micro')  # Error Type 2\n",
        "f1_error_3 = f1_score(y_test_error_incorrect_class, y_pred_model_8, labels=[2], average='micro')  # Error Type 3\n",
        "\n",
        "print(f\"Model Transformer Evaluation:\\n\"\n",
        "      f\"F1 Score for Error Type 1: {f1_error_1}\\n\"\n",
        "      f\"F1 Score for Error Type 2: {f1_error_2}\\n\"\n",
        "      f\"F1 Score for Error Type 3: {f1_error_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "CNUswR7OZLjG",
        "outputId": "b0fdacf2-c1bf-42fa-acbd-b274861e01c2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Transformer Evaluation:\n",
            "F1 Score for Error Type 1: 0.0\n",
            "F1 Score for Error Type 2: 0.75\n",
            "F1 Score for Error Type 3: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}