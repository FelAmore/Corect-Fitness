{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h54LkBEalW2",
        "outputId": "fd6d43a3-e18b-4383-f69c-d3f43a235525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (840, 88, 1)\n",
            "y_train_correct shape: (840,)\n",
            "y_train_error shape: (840, 3)\n",
            "X_test shape: (211, 88, 1)\n",
            "y_test_correct shape: (211,)\n",
            "y_test_error shape: (211, 3)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense\n",
        "import joblib\n",
        "\n",
        "# Step 1: Load CSV file\n",
        "data = pd.read_csv('/content/FINALLY_PUSHUP.csv')\n",
        "\n",
        "# Step 2: Separate keypoints and labels\n",
        "keypoints = data.iloc[:, 1:89].values  # Skip the first column (frame name) and take the next 88 columns\n",
        "correct_label = data['pose-label'].values  # Binary labels: 0 (incorrect), 1 (correct)\n",
        "error_type = data['error-label'].fillna('None').values  # Error types: None, Too-high-plank, Too-low-plank\n",
        "\n",
        "# Step 3: Normalize keypoints (Min-Max Scaling)\n",
        "scaler = MinMaxScaler()\n",
        "keypoints = scaler.fit_transform(keypoints)\n",
        "\n",
        "# Step 4: Reshape keypoints to (88, 1) for CNN input\n",
        "keypoints = keypoints.reshape(-1, 88, 1)\n",
        "\n",
        "# Step 5: Convert Error Type labels\n",
        "encoder = LabelEncoder()\n",
        "error_type_encoded = encoder.fit_transform(error_type)  # Encode error types as integers\n",
        "error_type_categorical = to_categorical(error_type_encoded)  # One-hot encode for categorical model\n",
        "\n",
        "# Step 6: Split data into training and testing sets\n",
        "X_train, X_test, y_train_correct, y_test_correct, y_train_error, y_test_error = train_test_split(\n",
        "    keypoints, correct_label, error_type_categorical, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Print data shapes to verify\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train_correct shape: {y_train_correct.shape}\")\n",
        "print(f\"y_train_error shape: {y_train_error.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test_correct shape: {y_test_correct.shape}\")\n",
        "print(f\"y_test_error shape: {y_test_error.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "-5LcAQPkbEoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_cnn_correct_incorrect():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(88, 1)),  # 88 keypoints as input\n",
        "        layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Step 1: Build the model\n",
        "model_1 = build_cnn_correct_incorrect()\n",
        "\n",
        "# Step 3: Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "history_1 = model_1.fit(\n",
        "    X_train, y_train_correct,\n",
        "    validation_data=(X_test, y_test_correct),\n",
        "    epochs=1000, batch_size=32, callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "model_1.save('/content/cnn_pose-label.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNieVhq9bFgh",
        "outputId": "eb524161-b4e4-46b6-a61e-1cecadd44015"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.6346 - loss: 0.6207 - val_accuracy: 0.7204 - val_loss: 0.5653\n",
            "Epoch 2/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7437 - loss: 0.5439 - val_accuracy: 0.7536 - val_loss: 0.5105\n",
            "Epoch 3/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7442 - loss: 0.4966 - val_accuracy: 0.7867 - val_loss: 0.4844\n",
            "Epoch 4/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7964 - loss: 0.4503 - val_accuracy: 0.7915 - val_loss: 0.4591\n",
            "Epoch 5/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8290 - loss: 0.4301 - val_accuracy: 0.8246 - val_loss: 0.3764\n",
            "Epoch 6/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8300 - loss: 0.3704 - val_accuracy: 0.7820 - val_loss: 0.4067\n",
            "Epoch 7/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8390 - loss: 0.3415 - val_accuracy: 0.8768 - val_loss: 0.3193\n",
            "Epoch 8/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8761 - loss: 0.3170 - val_accuracy: 0.8389 - val_loss: 0.3215\n",
            "Epoch 9/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8764 - loss: 0.2758 - val_accuracy: 0.8910 - val_loss: 0.2758\n",
            "Epoch 10/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8784 - loss: 0.2547 - val_accuracy: 0.8389 - val_loss: 0.3265\n",
            "Epoch 11/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8912 - loss: 0.2462 - val_accuracy: 0.9052 - val_loss: 0.2531\n",
            "Epoch 12/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9035 - loss: 0.2215 - val_accuracy: 0.8863 - val_loss: 0.2538\n",
            "Epoch 13/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8926 - loss: 0.2182 - val_accuracy: 0.8720 - val_loss: 0.2703\n",
            "Epoch 14/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8800 - loss: 0.2655 - val_accuracy: 0.8673 - val_loss: 0.2993\n",
            "Epoch 15/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9256 - loss: 0.2034 - val_accuracy: 0.9194 - val_loss: 0.2301\n",
            "Epoch 16/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9138 - loss: 0.1945 - val_accuracy: 0.8910 - val_loss: 0.2226\n",
            "Epoch 17/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9264 - loss: 0.1716 - val_accuracy: 0.8863 - val_loss: 0.2557\n",
            "Epoch 18/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9319 - loss: 0.1690 - val_accuracy: 0.8863 - val_loss: 0.2641\n",
            "Epoch 19/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9482 - loss: 0.1394 - val_accuracy: 0.9100 - val_loss: 0.2291\n",
            "Epoch 20/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9422 - loss: 0.1400 - val_accuracy: 0.9100 - val_loss: 0.2168\n",
            "Epoch 21/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9365 - loss: 0.1556 - val_accuracy: 0.9289 - val_loss: 0.1929\n",
            "Epoch 22/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9317 - loss: 0.1581 - val_accuracy: 0.9005 - val_loss: 0.2513\n",
            "Epoch 23/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9259 - loss: 0.1585 - val_accuracy: 0.9242 - val_loss: 0.2107\n",
            "Epoch 24/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9538 - loss: 0.1365 - val_accuracy: 0.9242 - val_loss: 0.2020\n",
            "Epoch 25/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9487 - loss: 0.1294 - val_accuracy: 0.9242 - val_loss: 0.1856\n",
            "Epoch 26/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9292 - loss: 0.1489 - val_accuracy: 0.9242 - val_loss: 0.1790\n",
            "Epoch 27/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9599 - loss: 0.1191 - val_accuracy: 0.9289 - val_loss: 0.1999\n",
            "Epoch 28/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9471 - loss: 0.1227 - val_accuracy: 0.9479 - val_loss: 0.1870\n",
            "Epoch 29/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9585 - loss: 0.1173 - val_accuracy: 0.9289 - val_loss: 0.1727\n",
            "Epoch 30/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9576 - loss: 0.1155 - val_accuracy: 0.9336 - val_loss: 0.1739\n",
            "Epoch 31/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9577 - loss: 0.1038 - val_accuracy: 0.9336 - val_loss: 0.1925\n",
            "Epoch 32/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9616 - loss: 0.0980 - val_accuracy: 0.9431 - val_loss: 0.1792\n",
            "Epoch 33/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9731 - loss: 0.0929 - val_accuracy: 0.9100 - val_loss: 0.2171\n",
            "Epoch 34/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9340 - loss: 0.1414 - val_accuracy: 0.9384 - val_loss: 0.1662\n",
            "Epoch 35/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9778 - loss: 0.0857 - val_accuracy: 0.9289 - val_loss: 0.1802\n",
            "Epoch 36/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9565 - loss: 0.0959 - val_accuracy: 0.9384 - val_loss: 0.2010\n",
            "Epoch 37/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9632 - loss: 0.0944 - val_accuracy: 0.9194 - val_loss: 0.2037\n",
            "Epoch 38/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9530 - loss: 0.1278 - val_accuracy: 0.9431 - val_loss: 0.1847\n",
            "Epoch 39/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9662 - loss: 0.0816 - val_accuracy: 0.9479 - val_loss: 0.1833\n",
            "Epoch 40/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9586 - loss: 0.0993 - val_accuracy: 0.9431 - val_loss: 0.1833\n",
            "Epoch 41/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9743 - loss: 0.0776 - val_accuracy: 0.9289 - val_loss: 0.2221\n",
            "Epoch 42/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9564 - loss: 0.1000 - val_accuracy: 0.9431 - val_loss: 0.1738\n",
            "Epoch 43/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9640 - loss: 0.0906 - val_accuracy: 0.9526 - val_loss: 0.1776\n",
            "Epoch 44/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9776 - loss: 0.0694 - val_accuracy: 0.9431 - val_loss: 0.1630\n",
            "Epoch 45/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9755 - loss: 0.0732 - val_accuracy: 0.9479 - val_loss: 0.1653\n",
            "Epoch 46/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9773 - loss: 0.0693 - val_accuracy: 0.9289 - val_loss: 0.2204\n",
            "Epoch 47/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9632 - loss: 0.0895 - val_accuracy: 0.9336 - val_loss: 0.1994\n",
            "Epoch 48/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9727 - loss: 0.0839 - val_accuracy: 0.9573 - val_loss: 0.1651\n",
            "Epoch 49/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9740 - loss: 0.0704 - val_accuracy: 0.9526 - val_loss: 0.1696\n",
            "Epoch 50/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9803 - loss: 0.0630 - val_accuracy: 0.9573 - val_loss: 0.1698\n",
            "Epoch 51/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9770 - loss: 0.0563 - val_accuracy: 0.9431 - val_loss: 0.2090\n",
            "Epoch 52/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9771 - loss: 0.0641 - val_accuracy: 0.9479 - val_loss: 0.1706\n",
            "Epoch 53/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9788 - loss: 0.0576 - val_accuracy: 0.9242 - val_loss: 0.2496\n",
            "Epoch 54/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9689 - loss: 0.0898 - val_accuracy: 0.9479 - val_loss: 0.1615\n",
            "Epoch 55/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9771 - loss: 0.0569 - val_accuracy: 0.9526 - val_loss: 0.1771\n",
            "Epoch 56/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9713 - loss: 0.0759 - val_accuracy: 0.9479 - val_loss: 0.1941\n",
            "Epoch 57/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9765 - loss: 0.0633 - val_accuracy: 0.9431 - val_loss: 0.1657\n",
            "Epoch 58/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9790 - loss: 0.0532 - val_accuracy: 0.9573 - val_loss: 0.1720\n",
            "Epoch 59/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9633 - loss: 0.0831 - val_accuracy: 0.9384 - val_loss: 0.2141\n",
            "Epoch 60/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9733 - loss: 0.0620 - val_accuracy: 0.9573 - val_loss: 0.1750\n",
            "Epoch 61/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9759 - loss: 0.0641 - val_accuracy: 0.9479 - val_loss: 0.2058\n",
            "Epoch 62/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9807 - loss: 0.0493 - val_accuracy: 0.9479 - val_loss: 0.1706\n",
            "Epoch 63/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9815 - loss: 0.0466 - val_accuracy: 0.9621 - val_loss: 0.1785\n",
            "Epoch 64/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9886 - loss: 0.0529 - val_accuracy: 0.9526 - val_loss: 0.1719\n",
            "Epoch 65/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9794 - loss: 0.0512 - val_accuracy: 0.9526 - val_loss: 0.1859\n",
            "Epoch 66/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9587 - loss: 0.0982 - val_accuracy: 0.9573 - val_loss: 0.1677\n",
            "Epoch 67/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9860 - loss: 0.0440 - val_accuracy: 0.9526 - val_loss: 0.1886\n",
            "Epoch 68/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9735 - loss: 0.0618 - val_accuracy: 0.9573 - val_loss: 0.1915\n",
            "Epoch 69/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0413 - val_accuracy: 0.9573 - val_loss: 0.1841\n",
            "Epoch 70/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9862 - loss: 0.0407 - val_accuracy: 0.9621 - val_loss: 0.1788\n",
            "Epoch 71/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0479 - val_accuracy: 0.9621 - val_loss: 0.1738\n",
            "Epoch 72/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9807 - loss: 0.0453 - val_accuracy: 0.9621 - val_loss: 0.1736\n",
            "Epoch 73/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9885 - loss: 0.0368 - val_accuracy: 0.9621 - val_loss: 0.1857\n",
            "Epoch 74/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9749 - loss: 0.0569 - val_accuracy: 0.9573 - val_loss: 0.1873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "# Model 1 predictions\n",
        "y_pred_model_1 = model_1.predict(X_test)  # Assuming 'model_1' is the trained model\n",
        "y_pred_model_1 = (y_pred_model_1 > 0.5)  # If binary classification, otherwise use softmax for multi-class\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_correct, y_pred_model_1)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test_correct, y_pred_model_1)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_test_correct, y_pred_model_1)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test_correct, y_pred_model_1)\n",
        "\n",
        "print(f\"Model CNN Evaluation:\\n\"\n",
        "      f\"Accuracy: {accuracy}\\n\"\n",
        "      f\"Precision: {precision}\\n\"\n",
        "      f\"Recall: {recall}\\n\"\n",
        "      f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn3lchT7buqt",
        "outputId": "fe18bedf-4786-49ad-b432-856f40660f8b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Model CNN Evaluation:\n",
            "Accuracy: 0.9478672985781991\n",
            "Precision: 0.9594594594594594\n",
            "Recall: 0.9659863945578231\n",
            "F1 Score: 0.9627118644067797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Updated build model function\n",
        "def build_cnn_error_classification():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(88, 1)),  # 88 keypoints as input\n",
        "        layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(3, activation='softmax')  # Multi-class classification output (3 classes)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Filter only incorrect samples for training Model 2\n",
        "X_train_incorrect = X_train[y_train_correct == 0]\n",
        "X_test_incorrect = X_test[y_test_correct == 0]\n",
        "y_train_error_incorrect = y_train_error[y_train_correct == 0]\n",
        "y_test_error_incorrect = y_test_error[y_test_correct == 0]\n",
        "\n",
        "# Check and reshape if necessary\n",
        "print(f\"Shape of y_train_error_incorrect before one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect before one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Only apply one-hot encoding if they are not already encoded\n",
        "if len(y_train_error_incorrect.shape) == 1:\n",
        "    y_train_error_incorrect = to_categorical(y_train_error_incorrect, num_classes=3)\n",
        "    y_test_error_incorrect = to_categorical(y_test_error_incorrect, num_classes=3)\n",
        "\n",
        "# Check shapes after one-hot encoding\n",
        "print(f\"Shape of y_train_error_incorrect after one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect after one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Train the model\n",
        "model_2 = build_cnn_error_classification()\n",
        "\n",
        "history_2 = model_2.fit(\n",
        "    X_train_incorrect, y_train_error_incorrect,\n",
        "    validation_data=(X_test_incorrect, y_test_error_incorrect),\n",
        "    epochs=50, batch_size=32\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model_2.save('/content/cnn_error-label.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWk83qvLb2My",
        "outputId": "a813994b-0c84-427f-dc54-510539e957df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train_error_incorrect before one-hot encoding: (294, 3)\n",
            "Shape of y_test_error_incorrect before one-hot encoding: (64, 3)\n",
            "Shape of y_train_error_incorrect after one-hot encoding: (294, 3)\n",
            "Shape of y_test_error_incorrect after one-hot encoding: (64, 3)\n",
            "Epoch 1/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.6241 - loss: 0.8547 - val_accuracy: 0.5469 - val_loss: 0.6603\n",
            "Epoch 2/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6826 - loss: 0.6356 - val_accuracy: 0.7344 - val_loss: 0.5821\n",
            "Epoch 3/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7406 - loss: 0.5897 - val_accuracy: 0.6094 - val_loss: 0.6025\n",
            "Epoch 4/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6930 - loss: 0.5587 - val_accuracy: 0.8750 - val_loss: 0.4535\n",
            "Epoch 5/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8063 - loss: 0.4840 - val_accuracy: 0.8906 - val_loss: 0.3997\n",
            "Epoch 6/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8219 - loss: 0.4413 - val_accuracy: 0.8438 - val_loss: 0.3599\n",
            "Epoch 7/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8374 - loss: 0.3758 - val_accuracy: 0.8750 - val_loss: 0.2991\n",
            "Epoch 8/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9070 - loss: 0.2960 - val_accuracy: 0.9219 - val_loss: 0.2716\n",
            "Epoch 9/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8675 - loss: 0.2600 - val_accuracy: 0.9375 - val_loss: 0.2211\n",
            "Epoch 10/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9344 - loss: 0.2129 - val_accuracy: 0.9062 - val_loss: 0.3400\n",
            "Epoch 11/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9154 - loss: 0.2204 - val_accuracy: 0.9062 - val_loss: 0.2720\n",
            "Epoch 12/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9235 - loss: 0.2152 - val_accuracy: 0.9219 - val_loss: 0.1768\n",
            "Epoch 13/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9589 - loss: 0.1535 - val_accuracy: 0.9219 - val_loss: 0.1722\n",
            "Epoch 14/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9468 - loss: 0.1328 - val_accuracy: 0.9219 - val_loss: 0.1636\n",
            "Epoch 15/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9531 - loss: 0.1208 - val_accuracy: 0.9375 - val_loss: 0.1744\n",
            "Epoch 16/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9730 - loss: 0.0822 - val_accuracy: 0.9375 - val_loss: 0.1515\n",
            "Epoch 17/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9539 - loss: 0.1061 - val_accuracy: 0.9375 - val_loss: 0.1605\n",
            "Epoch 18/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9660 - loss: 0.1011 - val_accuracy: 0.9531 - val_loss: 0.1482\n",
            "Epoch 19/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9663 - loss: 0.0835 - val_accuracy: 0.9375 - val_loss: 0.1294\n",
            "Epoch 20/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9704 - loss: 0.0824 - val_accuracy: 0.9375 - val_loss: 0.1515\n",
            "Epoch 21/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9796 - loss: 0.0724 - val_accuracy: 0.9375 - val_loss: 0.1246\n",
            "Epoch 22/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9550 - loss: 0.1065 - val_accuracy: 0.9375 - val_loss: 0.1261\n",
            "Epoch 23/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9780 - loss: 0.0784 - val_accuracy: 0.9375 - val_loss: 0.1306\n",
            "Epoch 24/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9523 - loss: 0.0979 - val_accuracy: 0.9219 - val_loss: 0.1500\n",
            "Epoch 25/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9740 - loss: 0.0692 - val_accuracy: 0.9375 - val_loss: 0.1127\n",
            "Epoch 26/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9757 - loss: 0.0721 - val_accuracy: 0.9531 - val_loss: 0.1110\n",
            "Epoch 27/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9807 - loss: 0.0654 - val_accuracy: 0.9375 - val_loss: 0.1381\n",
            "Epoch 28/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9810 - loss: 0.0559 - val_accuracy: 0.9531 - val_loss: 0.1056\n",
            "Epoch 29/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9811 - loss: 0.0560 - val_accuracy: 0.9531 - val_loss: 0.1092\n",
            "Epoch 30/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9784 - loss: 0.0550 - val_accuracy: 0.9531 - val_loss: 0.1103\n",
            "Epoch 31/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9894 - loss: 0.0391 - val_accuracy: 0.9531 - val_loss: 0.1044\n",
            "Epoch 32/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9929 - loss: 0.0372 - val_accuracy: 0.9531 - val_loss: 0.0927\n",
            "Epoch 33/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9966 - loss: 0.0363 - val_accuracy: 0.9531 - val_loss: 0.1146\n",
            "Epoch 34/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9723 - loss: 0.0708 - val_accuracy: 0.9531 - val_loss: 0.1339\n",
            "Epoch 35/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9815 - loss: 0.0447 - val_accuracy: 0.9531 - val_loss: 0.0971\n",
            "Epoch 36/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9917 - loss: 0.0343 - val_accuracy: 0.9688 - val_loss: 0.0792\n",
            "Epoch 37/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9809 - loss: 0.0568 - val_accuracy: 0.9531 - val_loss: 0.1081\n",
            "Epoch 38/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.0483 - val_accuracy: 0.9531 - val_loss: 0.0869\n",
            "Epoch 39/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9827 - loss: 0.0435 - val_accuracy: 0.9531 - val_loss: 0.0941\n",
            "Epoch 40/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9807 - loss: 0.0455 - val_accuracy: 0.9531 - val_loss: 0.1280\n",
            "Epoch 41/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9764 - loss: 0.0604 - val_accuracy: 0.9531 - val_loss: 0.0964\n",
            "Epoch 42/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9805 - loss: 0.0454 - val_accuracy: 0.9531 - val_loss: 0.0865\n",
            "Epoch 43/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0229 - val_accuracy: 0.9531 - val_loss: 0.0927\n",
            "Epoch 44/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9921 - loss: 0.0228 - val_accuracy: 0.9531 - val_loss: 0.0995\n",
            "Epoch 45/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9827 - loss: 0.0441 - val_accuracy: 0.9688 - val_loss: 0.1350\n",
            "Epoch 46/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9886 - loss: 0.0362 - val_accuracy: 0.9688 - val_loss: 0.0885\n",
            "Epoch 47/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9811 - loss: 0.0368 - val_accuracy: 0.9531 - val_loss: 0.0989\n",
            "Epoch 48/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 0.0213 - val_accuracy: 0.9531 - val_loss: 0.1042\n",
            "Epoch 49/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9899 - loss: 0.0254 - val_accuracy: 0.9531 - val_loss: 0.0864\n",
            "Epoch 50/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9885 - loss: 0.0377 - val_accuracy: 0.9844 - val_loss: 0.0583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convert true labels to class indices if they are one-hot encoded\n",
        "y_test_error_incorrect_class = np.argmax(y_test_error_incorrect, axis=1)\n",
        "\n",
        "# Model 2 predictions (assuming the model outputs class probabilities)\n",
        "y_pred_model_2 = model_2.predict(X_test_incorrect)  # Your model's predictions\n",
        "y_pred_model_2 = np.argmax(y_pred_model_2, axis=1)  # Convert predictions to class indices\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_error_incorrect_class, y_pred_model_2)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'],\n",
        "            yticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'])\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# F1-score for each error type (class)\n",
        "f1_error_1 = f1_score(y_test_error_incorrect_class, y_pred_model_2, labels=[0], average='micro')  # Error Type 1\n",
        "f1_error_2 = f1_score(y_test_error_incorrect_class, y_pred_model_2, labels=[1], average='micro')  # Error Type 2\n",
        "f1_error_3 = f1_score(y_test_error_incorrect_class, y_pred_model_2, labels=[2], average='micro')  # Error Type 3\n",
        "\n",
        "print(f\"Model CNN Evaluation:\\n\"\n",
        "      f\"F1 Score for Error Type 1: {f1_error_1}\\n\"\n",
        "      f\"F1 Score for Error Type 2: {f1_error_2}\\n\"\n",
        "      f\"F1 Score for Error Type 3: {f1_error_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "jGaDjM0pb9Iw",
        "outputId": "b1ea5a27-27d9-4544-bb08-1c29f0e50c2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model CNN Evaluation:\n",
            "F1 Score for Error Type 1: 0.0\n",
            "F1 Score for Error Type 2: 0.9714285714285714\n",
            "F1 Score for Error Type 3: 0.989247311827957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN with Attention"
      ],
      "metadata": {
        "id": "2hICOpVWb0ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_cnn_with_attention_correct_incorrect():\n",
        "    inputs = layers.Input(shape=(88, 1))\n",
        "    x = layers.Conv1D(32, kernel_size=3, activation='relu')(inputs)\n",
        "    x = layers.Conv1D(64, kernel_size=3, activation='relu')(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "    attention = layers.Attention()([x, x])  # Self-attention\n",
        "    x = layers.Flatten()(attention)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Step 1: Build the model\n",
        "model_3 = build_cnn_with_attention_correct_incorrect()\n",
        "\n",
        "# Step 3: Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "history_3 = model_3.fit(\n",
        "    X_train, y_train_correct,\n",
        "    validation_data=(X_test, y_test_correct),\n",
        "    epochs=1000, batch_size=32, callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "model_3.save('/content/cnn-with-attention_pose-label.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baUnOlA7cCBb",
        "outputId": "28dd4d04-493f-4a59-ca4b-56424fd4481f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5943 - loss: 0.6683 - val_accuracy: 0.6967 - val_loss: 0.5986\n",
            "Epoch 2/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6461 - loss: 0.6362 - val_accuracy: 0.7156 - val_loss: 0.6123\n",
            "Epoch 3/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6930 - loss: 0.6158 - val_accuracy: 0.7204 - val_loss: 0.5708\n",
            "Epoch 4/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7166 - loss: 0.5834 - val_accuracy: 0.7346 - val_loss: 0.5785\n",
            "Epoch 5/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6988 - loss: 0.5938 - val_accuracy: 0.7346 - val_loss: 0.5530\n",
            "Epoch 6/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7089 - loss: 0.5574 - val_accuracy: 0.5687 - val_loss: 0.6604\n",
            "Epoch 7/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6547 - loss: 0.5865 - val_accuracy: 0.7346 - val_loss: 0.5079\n",
            "Epoch 8/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7387 - loss: 0.5272 - val_accuracy: 0.7820 - val_loss: 0.5161\n",
            "Epoch 9/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7516 - loss: 0.5196 - val_accuracy: 0.7488 - val_loss: 0.4772\n",
            "Epoch 10/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7546 - loss: 0.4547 - val_accuracy: 0.7441 - val_loss: 0.5023\n",
            "Epoch 11/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7415 - loss: 0.5071 - val_accuracy: 0.7393 - val_loss: 0.4770\n",
            "Epoch 12/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7360 - loss: 0.4836 - val_accuracy: 0.7962 - val_loss: 0.4462\n",
            "Epoch 13/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7942 - loss: 0.4259 - val_accuracy: 0.6588 - val_loss: 0.6070\n",
            "Epoch 14/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7340 - loss: 0.5245 - val_accuracy: 0.8104 - val_loss: 0.4755\n",
            "Epoch 15/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7918 - loss: 0.4430 - val_accuracy: 0.8152 - val_loss: 0.4262\n",
            "Epoch 16/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7889 - loss: 0.4237 - val_accuracy: 0.7204 - val_loss: 0.5714\n",
            "Epoch 17/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7519 - loss: 0.4846 - val_accuracy: 0.7820 - val_loss: 0.5165\n",
            "Epoch 18/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7958 - loss: 0.4188 - val_accuracy: 0.8104 - val_loss: 0.3978\n",
            "Epoch 19/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8009 - loss: 0.3998 - val_accuracy: 0.7915 - val_loss: 0.3998\n",
            "Epoch 20/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8094 - loss: 0.4055 - val_accuracy: 0.7962 - val_loss: 0.4713\n",
            "Epoch 21/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7879 - loss: 0.4426 - val_accuracy: 0.8199 - val_loss: 0.4150\n",
            "Epoch 22/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7990 - loss: 0.3791 - val_accuracy: 0.8246 - val_loss: 0.3860\n",
            "Epoch 23/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8331 - loss: 0.3596 - val_accuracy: 0.8389 - val_loss: 0.3960\n",
            "Epoch 24/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8217 - loss: 0.4007 - val_accuracy: 0.8246 - val_loss: 0.3739\n",
            "Epoch 25/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7955 - loss: 0.3857 - val_accuracy: 0.8246 - val_loss: 0.3901\n",
            "Epoch 26/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8259 - loss: 0.3800 - val_accuracy: 0.8483 - val_loss: 0.3414\n",
            "Epoch 27/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8424 - loss: 0.3458 - val_accuracy: 0.8389 - val_loss: 0.3468\n",
            "Epoch 28/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8620 - loss: 0.3080 - val_accuracy: 0.8531 - val_loss: 0.3253\n",
            "Epoch 29/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8304 - loss: 0.3327 - val_accuracy: 0.8531 - val_loss: 0.3814\n",
            "Epoch 30/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8421 - loss: 0.3512 - val_accuracy: 0.8389 - val_loss: 0.3957\n",
            "Epoch 31/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8579 - loss: 0.3555 - val_accuracy: 0.8578 - val_loss: 0.3121\n",
            "Epoch 32/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8639 - loss: 0.3018 - val_accuracy: 0.8626 - val_loss: 0.3162\n",
            "Epoch 33/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8514 - loss: 0.3129 - val_accuracy: 0.8673 - val_loss: 0.3001\n",
            "Epoch 34/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8376 - loss: 0.3613 - val_accuracy: 0.8768 - val_loss: 0.3091\n",
            "Epoch 35/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8612 - loss: 0.3088 - val_accuracy: 0.8768 - val_loss: 0.3348\n",
            "Epoch 36/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8593 - loss: 0.3172 - val_accuracy: 0.8578 - val_loss: 0.2838\n",
            "Epoch 37/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8606 - loss: 0.2941 - val_accuracy: 0.8436 - val_loss: 0.4037\n",
            "Epoch 38/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8215 - loss: 0.3935 - val_accuracy: 0.8578 - val_loss: 0.2904\n",
            "Epoch 39/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8701 - loss: 0.2832 - val_accuracy: 0.8768 - val_loss: 0.2993\n",
            "Epoch 40/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8945 - loss: 0.2660 - val_accuracy: 0.8578 - val_loss: 0.2853\n",
            "Epoch 41/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8604 - loss: 0.2939 - val_accuracy: 0.8815 - val_loss: 0.3120\n",
            "Epoch 42/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8951 - loss: 0.2787 - val_accuracy: 0.9005 - val_loss: 0.2914\n",
            "Epoch 43/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8678 - loss: 0.2941 - val_accuracy: 0.8199 - val_loss: 0.3656\n",
            "Epoch 44/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7762 - loss: 0.4469 - val_accuracy: 0.8768 - val_loss: 0.3148\n",
            "Epoch 45/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8883 - loss: 0.2585 - val_accuracy: 0.8626 - val_loss: 0.3346\n",
            "Epoch 46/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8634 - loss: 0.2851 - val_accuracy: 0.8910 - val_loss: 0.2612\n",
            "Epoch 47/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8861 - loss: 0.2662 - val_accuracy: 0.9052 - val_loss: 0.2735\n",
            "Epoch 48/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9060 - loss: 0.2439 - val_accuracy: 0.9052 - val_loss: 0.2814\n",
            "Epoch 49/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8810 - loss: 0.2749 - val_accuracy: 0.9005 - val_loss: 0.2970\n",
            "Epoch 50/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9011 - loss: 0.2388 - val_accuracy: 0.9052 - val_loss: 0.2750\n",
            "Epoch 51/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8966 - loss: 0.2471 - val_accuracy: 0.8910 - val_loss: 0.2581\n",
            "Epoch 52/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8959 - loss: 0.2426 - val_accuracy: 0.9194 - val_loss: 0.2499\n",
            "Epoch 53/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9134 - loss: 0.2408 - val_accuracy: 0.9052 - val_loss: 0.2396\n",
            "Epoch 54/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9191 - loss: 0.2046 - val_accuracy: 0.9147 - val_loss: 0.2433\n",
            "Epoch 55/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9038 - loss: 0.2326 - val_accuracy: 0.8863 - val_loss: 0.2580\n",
            "Epoch 56/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9049 - loss: 0.2232 - val_accuracy: 0.9100 - val_loss: 0.2490\n",
            "Epoch 57/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9184 - loss: 0.2193 - val_accuracy: 0.9100 - val_loss: 0.2385\n",
            "Epoch 58/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8921 - loss: 0.2433 - val_accuracy: 0.9336 - val_loss: 0.2308\n",
            "Epoch 59/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9310 - loss: 0.1872 - val_accuracy: 0.9005 - val_loss: 0.2446\n",
            "Epoch 60/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9269 - loss: 0.2142 - val_accuracy: 0.8815 - val_loss: 0.3176\n",
            "Epoch 61/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9034 - loss: 0.2209 - val_accuracy: 0.9336 - val_loss: 0.2245\n",
            "Epoch 62/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9419 - loss: 0.1838 - val_accuracy: 0.9289 - val_loss: 0.2300\n",
            "Epoch 63/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9049 - loss: 0.2285 - val_accuracy: 0.9194 - val_loss: 0.2313\n",
            "Epoch 64/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9385 - loss: 0.1968 - val_accuracy: 0.9194 - val_loss: 0.2384\n",
            "Epoch 65/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9124 - loss: 0.2131 - val_accuracy: 0.8673 - val_loss: 0.3796\n",
            "Epoch 66/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8916 - loss: 0.2259 - val_accuracy: 0.9336 - val_loss: 0.2246\n",
            "Epoch 67/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9415 - loss: 0.1750 - val_accuracy: 0.8910 - val_loss: 0.2676\n",
            "Epoch 68/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9293 - loss: 0.1991 - val_accuracy: 0.9242 - val_loss: 0.2381\n",
            "Epoch 69/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9341 - loss: 0.1967 - val_accuracy: 0.9289 - val_loss: 0.2289\n",
            "Epoch 70/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9251 - loss: 0.2035 - val_accuracy: 0.9242 - val_loss: 0.2164\n",
            "Epoch 71/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9358 - loss: 0.2019 - val_accuracy: 0.9147 - val_loss: 0.2432\n",
            "Epoch 72/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9191 - loss: 0.2013 - val_accuracy: 0.9147 - val_loss: 0.2392\n",
            "Epoch 73/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9313 - loss: 0.1914 - val_accuracy: 0.9194 - val_loss: 0.2234\n",
            "Epoch 74/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9163 - loss: 0.2115 - val_accuracy: 0.9147 - val_loss: 0.2282\n",
            "Epoch 75/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9291 - loss: 0.1967 - val_accuracy: 0.8720 - val_loss: 0.3435\n",
            "Epoch 76/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8696 - loss: 0.2751 - val_accuracy: 0.8720 - val_loss: 0.2989\n",
            "Epoch 77/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8821 - loss: 0.2747 - val_accuracy: 0.8199 - val_loss: 0.4798\n",
            "Epoch 78/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8986 - loss: 0.2146 - val_accuracy: 0.9336 - val_loss: 0.2183\n",
            "Epoch 79/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9152 - loss: 0.1929 - val_accuracy: 0.8863 - val_loss: 0.2533\n",
            "Epoch 80/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9304 - loss: 0.1863 - val_accuracy: 0.9384 - val_loss: 0.2184\n",
            "Epoch 81/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9063 - loss: 0.2276 - val_accuracy: 0.9431 - val_loss: 0.2109\n",
            "Epoch 82/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9384 - loss: 0.1767 - val_accuracy: 0.9242 - val_loss: 0.2341\n",
            "Epoch 83/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9445 - loss: 0.1756 - val_accuracy: 0.9005 - val_loss: 0.2658\n",
            "Epoch 84/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9379 - loss: 0.1723 - val_accuracy: 0.9242 - val_loss: 0.2321\n",
            "Epoch 85/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9512 - loss: 0.1614 - val_accuracy: 0.9384 - val_loss: 0.2251\n",
            "Epoch 86/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9317 - loss: 0.1729 - val_accuracy: 0.9431 - val_loss: 0.2139\n",
            "Epoch 87/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9569 - loss: 0.1470 - val_accuracy: 0.9194 - val_loss: 0.2439\n",
            "Epoch 88/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9407 - loss: 0.1723 - val_accuracy: 0.9147 - val_loss: 0.2301\n",
            "Epoch 89/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9270 - loss: 0.1861 - val_accuracy: 0.8768 - val_loss: 0.2969\n",
            "Epoch 90/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9395 - loss: 0.1545 - val_accuracy: 0.9147 - val_loss: 0.2639\n",
            "Epoch 91/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9324 - loss: 0.1692 - val_accuracy: 0.9147 - val_loss: 0.2667\n",
            "Epoch 92/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9445 - loss: 0.1616 - val_accuracy: 0.9242 - val_loss: 0.2356\n",
            "Epoch 93/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9558 - loss: 0.1437 - val_accuracy: 0.9336 - val_loss: 0.2149\n",
            "Epoch 94/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9425 - loss: 0.1655 - val_accuracy: 0.8578 - val_loss: 0.3945\n",
            "Epoch 95/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9263 - loss: 0.1893 - val_accuracy: 0.9147 - val_loss: 0.2469\n",
            "Epoch 96/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9431 - loss: 0.1579 - val_accuracy: 0.9242 - val_loss: 0.2296\n",
            "Epoch 97/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9474 - loss: 0.1370 - val_accuracy: 0.9336 - val_loss: 0.2197\n",
            "Epoch 98/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9638 - loss: 0.1188 - val_accuracy: 0.9242 - val_loss: 0.2342\n",
            "Epoch 99/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9322 - loss: 0.1748 - val_accuracy: 0.9336 - val_loss: 0.2269\n",
            "Epoch 100/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9295 - loss: 0.1588 - val_accuracy: 0.9431 - val_loss: 0.2155\n",
            "Epoch 101/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9151 - loss: 0.2220 - val_accuracy: 0.9242 - val_loss: 0.2239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "# Model 1 predictions\n",
        "y_pred_model_3 = model_3.predict(X_test)  # Assuming 'model_1' is the trained model\n",
        "y_pred_model_3 = (y_pred_model_3 > 0.5)  # If binary classification, otherwise use softmax for multi-class\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_correct, y_pred_model_3)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test_correct, y_pred_model_3)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_test_correct, y_pred_model_3)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test_correct, y_pred_model_3)\n",
        "\n",
        "print(f\"Model CNN with Attention Evaluation:\\n\"\n",
        "      f\"Accuracy: {accuracy}\\n\"\n",
        "      f\"Precision: {precision}\\n\"\n",
        "      f\"Recall: {recall}\\n\"\n",
        "      f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoY4o4hFcYfU",
        "outputId": "8d4f1701-18a9-4a1c-c880-751211b4b666"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 285ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 16 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d9bb4cf2830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Model CNN with Attention Evaluation:\n",
            "Accuracy: 0.943127962085308\n",
            "Precision: 0.972027972027972\n",
            "Recall: 0.9455782312925171\n",
            "F1 Score: 0.9586206896551724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Updated build model function\n",
        "def build_cnn_with_attention_error_classification():\n",
        "    inputs = layers.Input(shape=(88, 1))\n",
        "    x = layers.Conv1D(32, kernel_size=3, activation='relu')(inputs)\n",
        "    x = layers.Conv1D(64, kernel_size=3, activation='relu')(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "    attention = layers.Attention()([x, x])  # Self-attention\n",
        "    x = layers.Flatten()(attention)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    outputs = layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Filter only incorrect samples for training Model 2\n",
        "X_train_incorrect = X_train[y_train_correct == 0]\n",
        "X_test_incorrect = X_test[y_test_correct == 0]\n",
        "y_train_error_incorrect = y_train_error[y_train_correct == 0]\n",
        "y_test_error_incorrect = y_test_error[y_test_correct == 0]\n",
        "\n",
        "# Check and reshape if necessary\n",
        "print(f\"Shape of y_train_error_incorrect before one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect before one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Only apply one-hot encoding if they are not already encoded\n",
        "if len(y_train_error_incorrect.shape) == 1:\n",
        "    y_train_error_incorrect = to_categorical(y_train_error_incorrect, num_classes=3)\n",
        "    y_test_error_incorrect = to_categorical(y_test_error_incorrect, num_classes=3)\n",
        "\n",
        "# Check shapes after one-hot encoding\n",
        "print(f\"Shape of y_train_error_incorrect after one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect after one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Train the model\n",
        "model_4 = build_cnn_error_classification()\n",
        "\n",
        "history_4 = model_4.fit(\n",
        "    X_train_incorrect, y_train_error_incorrect,\n",
        "    validation_data=(X_test_incorrect, y_test_error_incorrect),\n",
        "    epochs=50, batch_size=32\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model_4.save('/content/cnn-with-attention_error-label.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1ndgWbWccc3",
        "outputId": "7bfa9bcb-4794-49d9-c0c3-ed898b6d3b2f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train_error_incorrect before one-hot encoding: (294, 3)\n",
            "Shape of y_test_error_incorrect before one-hot encoding: (64, 3)\n",
            "Shape of y_train_error_incorrect after one-hot encoding: (294, 3)\n",
            "Shape of y_test_error_incorrect after one-hot encoding: (64, 3)\n",
            "Epoch 1/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.6222 - loss: 0.8359 - val_accuracy: 0.7969 - val_loss: 0.5631\n",
            "Epoch 2/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8143 - loss: 0.5635 - val_accuracy: 0.7500 - val_loss: 0.5346\n",
            "Epoch 3/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8113 - loss: 0.4816 - val_accuracy: 0.8125 - val_loss: 0.4595\n",
            "Epoch 4/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8060 - loss: 0.4568 - val_accuracy: 0.8438 - val_loss: 0.3566\n",
            "Epoch 5/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9052 - loss: 0.3330 - val_accuracy: 0.9219 - val_loss: 0.2844\n",
            "Epoch 6/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8381 - loss: 0.3445 - val_accuracy: 0.9375 - val_loss: 0.2561\n",
            "Epoch 7/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9014 - loss: 0.2604 - val_accuracy: 0.9219 - val_loss: 0.2195\n",
            "Epoch 8/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9309 - loss: 0.1959 - val_accuracy: 0.9375 - val_loss: 0.1811\n",
            "Epoch 9/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9178 - loss: 0.1832 - val_accuracy: 0.9219 - val_loss: 0.1839\n",
            "Epoch 10/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9641 - loss: 0.1525 - val_accuracy: 0.9219 - val_loss: 0.1725\n",
            "Epoch 11/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9529 - loss: 0.1148 - val_accuracy: 0.9219 - val_loss: 0.1716\n",
            "Epoch 12/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9666 - loss: 0.1078 - val_accuracy: 0.9375 - val_loss: 0.1916\n",
            "Epoch 13/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9637 - loss: 0.1015 - val_accuracy: 0.9375 - val_loss: 0.1639\n",
            "Epoch 14/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9742 - loss: 0.1216 - val_accuracy: 0.9375 - val_loss: 0.1738\n",
            "Epoch 15/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9701 - loss: 0.1036 - val_accuracy: 0.9219 - val_loss: 0.1573\n",
            "Epoch 16/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9791 - loss: 0.0771 - val_accuracy: 0.9375 - val_loss: 0.2043\n",
            "Epoch 17/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9639 - loss: 0.1199 - val_accuracy: 0.9375 - val_loss: 0.1248\n",
            "Epoch 18/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9792 - loss: 0.0669 - val_accuracy: 0.9531 - val_loss: 0.1262\n",
            "Epoch 19/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9803 - loss: 0.0623 - val_accuracy: 0.9375 - val_loss: 0.1212\n",
            "Epoch 20/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9610 - loss: 0.0938 - val_accuracy: 0.9531 - val_loss: 0.1204\n",
            "Epoch 21/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9781 - loss: 0.0684 - val_accuracy: 0.9531 - val_loss: 0.1292\n",
            "Epoch 22/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9811 - loss: 0.0578 - val_accuracy: 0.9531 - val_loss: 0.1110\n",
            "Epoch 23/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9770 - loss: 0.0569 - val_accuracy: 0.9375 - val_loss: 0.1112\n",
            "Epoch 24/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9763 - loss: 0.0679 - val_accuracy: 0.9531 - val_loss: 0.1053\n",
            "Epoch 25/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9688 - loss: 0.0824 - val_accuracy: 0.9531 - val_loss: 0.1106\n",
            "Epoch 26/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9889 - loss: 0.0499 - val_accuracy: 0.9375 - val_loss: 0.1057\n",
            "Epoch 27/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9746 - loss: 0.0595 - val_accuracy: 0.9531 - val_loss: 0.2050\n",
            "Epoch 28/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9627 - loss: 0.1124 - val_accuracy: 0.9375 - val_loss: 0.0995\n",
            "Epoch 29/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9972 - loss: 0.0368 - val_accuracy: 0.9531 - val_loss: 0.1238\n",
            "Epoch 30/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9895 - loss: 0.0398 - val_accuracy: 0.9531 - val_loss: 0.1108\n",
            "Epoch 31/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9628 - loss: 0.0685 - val_accuracy: 0.9688 - val_loss: 0.1247\n",
            "Epoch 32/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9561 - loss: 0.0908 - val_accuracy: 0.9531 - val_loss: 0.1772\n",
            "Epoch 33/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9592 - loss: 0.1012 - val_accuracy: 0.9688 - val_loss: 0.1001\n",
            "Epoch 34/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9901 - loss: 0.0439 - val_accuracy: 0.9531 - val_loss: 0.1179\n",
            "Epoch 35/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9812 - loss: 0.0392 - val_accuracy: 0.9375 - val_loss: 0.1095\n",
            "Epoch 36/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9824 - loss: 0.0426 - val_accuracy: 0.9531 - val_loss: 0.1005\n",
            "Epoch 37/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9906 - loss: 0.0265 - val_accuracy: 0.9531 - val_loss: 0.1043\n",
            "Epoch 38/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9800 - loss: 0.0542 - val_accuracy: 0.9531 - val_loss: 0.1018\n",
            "Epoch 39/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9692 - loss: 0.0702 - val_accuracy: 0.9688 - val_loss: 0.1327\n",
            "Epoch 40/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9739 - loss: 0.0754 - val_accuracy: 0.9688 - val_loss: 0.1311\n",
            "Epoch 41/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9687 - loss: 0.0691 - val_accuracy: 0.9688 - val_loss: 0.1080\n",
            "Epoch 42/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9926 - loss: 0.0326 - val_accuracy: 0.9688 - val_loss: 0.0786\n",
            "Epoch 43/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9738 - loss: 0.0471 - val_accuracy: 0.9531 - val_loss: 0.1025\n",
            "Epoch 44/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9774 - loss: 0.0372 - val_accuracy: 0.9531 - val_loss: 0.0953\n",
            "Epoch 45/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9978 - loss: 0.0270 - val_accuracy: 0.9531 - val_loss: 0.0898\n",
            "Epoch 46/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9935 - loss: 0.0217 - val_accuracy: 0.9531 - val_loss: 0.0874\n",
            "Epoch 47/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 0.9531 - val_loss: 0.0831\n",
            "Epoch 48/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9966 - loss: 0.0167 - val_accuracy: 0.9531 - val_loss: 0.0762\n",
            "Epoch 49/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.9531 - val_loss: 0.0798\n",
            "Epoch 50/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9887 - loss: 0.0198 - val_accuracy: 0.9531 - val_loss: 0.0821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convert true labels to class indices if they are one-hot encoded\n",
        "y_test_error_incorrect_class = np.argmax(y_test_error_incorrect, axis=1)\n",
        "\n",
        "# Model 2 predictions (assuming the model outputs class probabilities)\n",
        "y_pred_model_4 = model_4.predict(X_test_incorrect)  # Your model's predictions\n",
        "y_pred_model_4 = np.argmax(y_pred_model_4, axis=1)  # Convert predictions to class indices\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_error_incorrect_class, y_pred_model_4)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'],\n",
        "            yticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'])\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# F1-score for each error type (class)\n",
        "f1_error_1 = f1_score(y_test_error_incorrect_class, y_pred_model_4, labels=[0], average='micro')  # Error Type 1\n",
        "f1_error_2 = f1_score(y_test_error_incorrect_class, y_pred_model_4, labels=[1], average='micro')  # Error Type 2\n",
        "f1_error_3 = f1_score(y_test_error_incorrect_class, y_pred_model_4, labels=[2], average='micro')  # Error Type 3\n",
        "\n",
        "print(f\"Model CNN with Attention Evaluation:\\n\"\n",
        "      f\"F1 Score for Error Type 1: {f1_error_1}\\n\"\n",
        "      f\"F1 Score for Error Type 2: {f1_error_2}\\n\"\n",
        "      f\"F1 Score for Error Type 3: {f1_error_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "vZwu7bMucjfg",
        "outputId": "4a0d1a70-cbdf-4704-ccbe-283231a30581"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d9bb4db1f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model CNN with Attention Evaluation:\n",
            "F1 Score for Error Type 1: 0.0\n",
            "F1 Score for Error Type 2: 0.918918918918919\n",
            "F1 Score for Error Type 3: 0.967032967032967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG"
      ],
      "metadata": {
        "id": "NlG2vcMFcnpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_vgg_correct_incorrect():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(88, 1)),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Step 1: Build the model\n",
        "model_5 = build_vgg_correct_incorrect()\n",
        "\n",
        "# Step 3: Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "history_5 = model_5.fit(\n",
        "    X_train, y_train_correct,\n",
        "    validation_data=(X_test, y_test_correct),\n",
        "    epochs=1000, batch_size=32, callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "model_5.save('/content/vgg_pose-label.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik9hnDGlcm25",
        "outputId": "9a739e0d-90fb-49c8-8ac2-0392884c3320"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6081 - loss: 0.6419 - val_accuracy: 0.7156 - val_loss: 0.5657\n",
            "Epoch 2/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7330 - loss: 0.5508 - val_accuracy: 0.7393 - val_loss: 0.4949\n",
            "Epoch 3/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7692 - loss: 0.4824 - val_accuracy: 0.8341 - val_loss: 0.3232\n",
            "Epoch 4/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8316 - loss: 0.3372 - val_accuracy: 0.7915 - val_loss: 0.4202\n",
            "Epoch 5/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8293 - loss: 0.3717 - val_accuracy: 0.9005 - val_loss: 0.2579\n",
            "Epoch 6/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8739 - loss: 0.2948 - val_accuracy: 0.8815 - val_loss: 0.2756\n",
            "Epoch 7/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8703 - loss: 0.2666 - val_accuracy: 0.8768 - val_loss: 0.2652\n",
            "Epoch 8/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8900 - loss: 0.2368 - val_accuracy: 0.9147 - val_loss: 0.1906\n",
            "Epoch 9/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9249 - loss: 0.1784 - val_accuracy: 0.8910 - val_loss: 0.2098\n",
            "Epoch 10/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8969 - loss: 0.2103 - val_accuracy: 0.9289 - val_loss: 0.1671\n",
            "Epoch 11/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9329 - loss: 0.1677 - val_accuracy: 0.8863 - val_loss: 0.2866\n",
            "Epoch 12/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9165 - loss: 0.1983 - val_accuracy: 0.9384 - val_loss: 0.1742\n",
            "Epoch 13/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9268 - loss: 0.1666 - val_accuracy: 0.9194 - val_loss: 0.1676\n",
            "Epoch 14/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9294 - loss: 0.1659 - val_accuracy: 0.9194 - val_loss: 0.2069\n",
            "Epoch 15/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9310 - loss: 0.1580 - val_accuracy: 0.9147 - val_loss: 0.1931\n",
            "Epoch 16/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9471 - loss: 0.1337 - val_accuracy: 0.9147 - val_loss: 0.2108\n",
            "Epoch 17/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9435 - loss: 0.1428 - val_accuracy: 0.9052 - val_loss: 0.2136\n",
            "Epoch 18/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9538 - loss: 0.1188 - val_accuracy: 0.9289 - val_loss: 0.1867\n",
            "Epoch 19/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9660 - loss: 0.1001 - val_accuracy: 0.9194 - val_loss: 0.2197\n",
            "Epoch 20/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9453 - loss: 0.1254 - val_accuracy: 0.9384 - val_loss: 0.1874\n",
            "Epoch 21/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9504 - loss: 0.1191 - val_accuracy: 0.9621 - val_loss: 0.1477\n",
            "Epoch 22/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9648 - loss: 0.0873 - val_accuracy: 0.9431 - val_loss: 0.1738\n",
            "Epoch 23/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9609 - loss: 0.0877 - val_accuracy: 0.9526 - val_loss: 0.1453\n",
            "Epoch 24/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9686 - loss: 0.0879 - val_accuracy: 0.9336 - val_loss: 0.2126\n",
            "Epoch 25/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9552 - loss: 0.1217 - val_accuracy: 0.9526 - val_loss: 0.1698\n",
            "Epoch 26/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9704 - loss: 0.0872 - val_accuracy: 0.9242 - val_loss: 0.2994\n",
            "Epoch 27/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9785 - loss: 0.0785 - val_accuracy: 0.9384 - val_loss: 0.2086\n",
            "Epoch 28/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9647 - loss: 0.0777 - val_accuracy: 0.9621 - val_loss: 0.1502\n",
            "Epoch 29/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9722 - loss: 0.0673 - val_accuracy: 0.9479 - val_loss: 0.1706\n",
            "Epoch 30/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9636 - loss: 0.0709 - val_accuracy: 0.9479 - val_loss: 0.2031\n",
            "Epoch 31/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9658 - loss: 0.0779 - val_accuracy: 0.9573 - val_loss: 0.1354\n",
            "Epoch 32/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9617 - loss: 0.1075 - val_accuracy: 0.9526 - val_loss: 0.1718\n",
            "Epoch 33/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9801 - loss: 0.0554 - val_accuracy: 0.9573 - val_loss: 0.1426\n",
            "Epoch 34/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9651 - loss: 0.0828 - val_accuracy: 0.9431 - val_loss: 0.1683\n",
            "Epoch 35/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9699 - loss: 0.0725 - val_accuracy: 0.9479 - val_loss: 0.1562\n",
            "Epoch 36/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9781 - loss: 0.0547 - val_accuracy: 0.9526 - val_loss: 0.1718\n",
            "Epoch 37/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9738 - loss: 0.0622 - val_accuracy: 0.9668 - val_loss: 0.1696\n",
            "Epoch 38/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9691 - loss: 0.0652 - val_accuracy: 0.9479 - val_loss: 0.2077\n",
            "Epoch 39/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9661 - loss: 0.0742 - val_accuracy: 0.9479 - val_loss: 0.1833\n",
            "Epoch 40/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9712 - loss: 0.0618 - val_accuracy: 0.9573 - val_loss: 0.1581\n",
            "Epoch 41/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9735 - loss: 0.0719 - val_accuracy: 0.9668 - val_loss: 0.1534\n",
            "Epoch 42/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9821 - loss: 0.0519 - val_accuracy: 0.9526 - val_loss: 0.1805\n",
            "Epoch 43/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9783 - loss: 0.0616 - val_accuracy: 0.9621 - val_loss: 0.1583\n",
            "Epoch 44/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9712 - loss: 0.0694 - val_accuracy: 0.9526 - val_loss: 0.1907\n",
            "Epoch 45/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9784 - loss: 0.0679 - val_accuracy: 0.9289 - val_loss: 0.2791\n",
            "Epoch 46/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9697 - loss: 0.0774 - val_accuracy: 0.9573 - val_loss: 0.1830\n",
            "Epoch 47/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9889 - loss: 0.0329 - val_accuracy: 0.9621 - val_loss: 0.1744\n",
            "Epoch 48/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.9895 - loss: 0.0392 - val_accuracy: 0.9621 - val_loss: 0.1878\n",
            "Epoch 49/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9901 - loss: 0.0333 - val_accuracy: 0.9621 - val_loss: 0.1950\n",
            "Epoch 50/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9754 - loss: 0.0592 - val_accuracy: 0.9289 - val_loss: 0.2904\n",
            "Epoch 51/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9774 - loss: 0.0761 - val_accuracy: 0.9431 - val_loss: 0.2278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "# Model 1 predictions\n",
        "y_pred_model_5 = model_5.predict(X_test)  # Assuming 'model_1' is the trained model\n",
        "y_pred_model_5 = (y_pred_model_5 > 0.5)  # If binary classification, otherwise use softmax for multi-class\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_correct, y_pred_model_5)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test_correct, y_pred_model_5)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_test_correct, y_pred_model_5)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test_correct, y_pred_model_5)\n",
        "\n",
        "print(f\"Model VGG Evaluation:\\n\"\n",
        "      f\"Accuracy: {accuracy}\\n\"\n",
        "      f\"Precision: {precision}\\n\"\n",
        "      f\"Recall: {recall}\\n\"\n",
        "      f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pMLa-svc780",
        "outputId": "9a0b6c92-7a52-4cfb-e13c-7b282c7ab564"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "Model VGG Evaluation:\n",
            "Accuracy: 0.957345971563981\n",
            "Precision: 0.9662162162162162\n",
            "Recall: 0.9727891156462585\n",
            "F1 Score: 0.9694915254237289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Updated build model function\n",
        "def build_vgg_error_classification():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(88, 1)),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Filter only incorrect samples for training Model 2\n",
        "X_train_incorrect = X_train[y_train_correct == 0]\n",
        "X_test_incorrect = X_test[y_test_correct == 0]\n",
        "y_train_error_incorrect = y_train_error[y_train_correct == 0]\n",
        "y_test_error_incorrect = y_test_error[y_test_correct == 0]\n",
        "\n",
        "# Check and reshape if necessary\n",
        "print(f\"Shape of y_train_error_incorrect before one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect before one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Only apply one-hot encoding if they are not already encoded\n",
        "if len(y_train_error_incorrect.shape) == 1:\n",
        "    y_train_error_incorrect = to_categorical(y_train_error_incorrect, num_classes=3)\n",
        "    y_test_error_incorrect = to_categorical(y_test_error_incorrect, num_classes=3)\n",
        "\n",
        "# Check shapes after one-hot encoding\n",
        "print(f\"Shape of y_train_error_incorrect after one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect after one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Train the model\n",
        "model_6 = build_vgg_error_classification()\n",
        "\n",
        "history_6 = model_6.fit(\n",
        "    X_train_incorrect, y_train_error_incorrect,\n",
        "    validation_data=(X_test_incorrect, y_test_error_incorrect),\n",
        "    epochs=50, batch_size=32\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model_6.save('/content/vgg_error-label.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb1jy9VAc_gv",
        "outputId": "ccc9f815-cad0-464a-d3a2-87b1785dfde1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train_error_incorrect before one-hot encoding: (294, 3)\n",
            "Shape of y_test_error_incorrect before one-hot encoding: (64, 3)\n",
            "Shape of y_train_error_incorrect after one-hot encoding: (294, 3)\n",
            "Shape of y_test_error_incorrect after one-hot encoding: (64, 3)\n",
            "Epoch 1/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.5233 - loss: 0.8762 - val_accuracy: 0.7188 - val_loss: 0.5261\n",
            "Epoch 2/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6334 - loss: 0.6423 - val_accuracy: 0.8906 - val_loss: 0.4886\n",
            "Epoch 3/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7635 - loss: 0.5680 - val_accuracy: 0.7188 - val_loss: 0.4546\n",
            "Epoch 4/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7070 - loss: 0.5558 - val_accuracy: 0.9062 - val_loss: 0.3752\n",
            "Epoch 5/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8550 - loss: 0.3645 - val_accuracy: 0.8906 - val_loss: 0.2175\n",
            "Epoch 6/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9162 - loss: 0.2219 - val_accuracy: 0.9062 - val_loss: 0.2678\n",
            "Epoch 7/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9360 - loss: 0.2019 - val_accuracy: 0.9062 - val_loss: 0.2621\n",
            "Epoch 8/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9564 - loss: 0.1405 - val_accuracy: 0.9219 - val_loss: 0.1351\n",
            "Epoch 9/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9649 - loss: 0.0960 - val_accuracy: 0.9375 - val_loss: 0.1384\n",
            "Epoch 10/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9596 - loss: 0.0735 - val_accuracy: 0.9219 - val_loss: 0.1265\n",
            "Epoch 11/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9738 - loss: 0.0630 - val_accuracy: 0.9688 - val_loss: 0.1067\n",
            "Epoch 12/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9857 - loss: 0.0523 - val_accuracy: 0.9219 - val_loss: 0.1259\n",
            "Epoch 13/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9694 - loss: 0.0714 - val_accuracy: 0.9531 - val_loss: 0.1235\n",
            "Epoch 14/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9644 - loss: 0.0783 - val_accuracy: 0.9531 - val_loss: 0.1615\n",
            "Epoch 15/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9672 - loss: 0.0684 - val_accuracy: 0.9531 - val_loss: 0.1055\n",
            "Epoch 16/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9795 - loss: 0.0606 - val_accuracy: 0.9375 - val_loss: 0.1078\n",
            "Epoch 17/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9801 - loss: 0.0517 - val_accuracy: 0.9531 - val_loss: 0.1419\n",
            "Epoch 18/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9855 - loss: 0.0484 - val_accuracy: 0.9375 - val_loss: 0.0927\n",
            "Epoch 19/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9794 - loss: 0.0498 - val_accuracy: 0.9219 - val_loss: 0.1468\n",
            "Epoch 20/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9820 - loss: 0.0478 - val_accuracy: 0.9375 - val_loss: 0.1212\n",
            "Epoch 21/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9843 - loss: 0.0443 - val_accuracy: 0.9688 - val_loss: 0.0576\n",
            "Epoch 22/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9888 - loss: 0.0309 - val_accuracy: 0.9844 - val_loss: 0.0879\n",
            "Epoch 23/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9833 - loss: 0.0570 - val_accuracy: 0.9531 - val_loss: 0.1168\n",
            "Epoch 24/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9893 - loss: 0.0220 - val_accuracy: 0.9531 - val_loss: 0.0740\n",
            "Epoch 25/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9938 - loss: 0.0196 - val_accuracy: 0.9688 - val_loss: 0.0540\n",
            "Epoch 26/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9854 - loss: 0.0317 - val_accuracy: 0.9688 - val_loss: 0.1003\n",
            "Epoch 27/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0105 - val_accuracy: 0.9688 - val_loss: 0.0726\n",
            "Epoch 28/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9956 - loss: 0.0211 - val_accuracy: 0.9531 - val_loss: 0.1028\n",
            "Epoch 29/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9842 - loss: 0.0347 - val_accuracy: 0.9844 - val_loss: 0.0639\n",
            "Epoch 30/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9853 - loss: 0.0264 - val_accuracy: 0.9844 - val_loss: 0.0473\n",
            "Epoch 31/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9791 - loss: 0.0682 - val_accuracy: 0.9531 - val_loss: 0.1694\n",
            "Epoch 32/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9869 - loss: 0.0422 - val_accuracy: 0.9531 - val_loss: 0.2252\n",
            "Epoch 33/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9656 - loss: 0.1119 - val_accuracy: 0.9844 - val_loss: 0.0686\n",
            "Epoch 34/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9912 - loss: 0.0410 - val_accuracy: 0.9531 - val_loss: 0.0610\n",
            "Epoch 35/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9889 - loss: 0.0238 - val_accuracy: 0.9688 - val_loss: 0.0717\n",
            "Epoch 36/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9970 - loss: 0.0170 - val_accuracy: 0.9531 - val_loss: 0.0986\n",
            "Epoch 37/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9790 - loss: 0.0262 - val_accuracy: 0.9531 - val_loss: 0.0635\n",
            "Epoch 38/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9966 - loss: 0.0119 - val_accuracy: 0.9531 - val_loss: 0.1273\n",
            "Epoch 39/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9893 - loss: 0.0133 - val_accuracy: 0.9531 - val_loss: 0.0811\n",
            "Epoch 40/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9994 - loss: 0.0062 - val_accuracy: 0.9688 - val_loss: 0.0676\n",
            "Epoch 41/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9814 - loss: 0.0680 - val_accuracy: 0.9375 - val_loss: 0.2089\n",
            "Epoch 42/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9653 - loss: 0.0867 - val_accuracy: 0.9531 - val_loss: 0.0764\n",
            "Epoch 43/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9860 - loss: 0.0257 - val_accuracy: 0.9531 - val_loss: 0.0720\n",
            "Epoch 44/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0125 - val_accuracy: 0.9375 - val_loss: 0.1065\n",
            "Epoch 45/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9956 - loss: 0.0128 - val_accuracy: 0.9375 - val_loss: 0.0913\n",
            "Epoch 46/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9375 - val_loss: 0.1608\n",
            "Epoch 47/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9920 - loss: 0.0131 - val_accuracy: 0.9375 - val_loss: 0.1242\n",
            "Epoch 48/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9929 - loss: 0.0206 - val_accuracy: 0.9375 - val_loss: 0.1436\n",
            "Epoch 49/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9531 - val_loss: 0.1138\n",
            "Epoch 50/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9531 - val_loss: 0.1229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convert true labels to class indices if they are one-hot encoded\n",
        "y_test_error_incorrect_class = np.argmax(y_test_error_incorrect, axis=1)\n",
        "\n",
        "# Model 2 predictions (assuming the model outputs class probabilities)\n",
        "y_pred_model_6 = model_6.predict(X_test_incorrect)  # Your model's predictions\n",
        "y_pred_model_6 = np.argmax(y_pred_model_6, axis=1)  # Convert predictions to class indices\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_error_incorrect_class, y_pred_model_6)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'],\n",
        "            yticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'])\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# F1-score for each error type (class)\n",
        "f1_error_1 = f1_score(y_test_error_incorrect_class, y_pred_model_6, labels=[0], average='micro')  # Error Type 1\n",
        "f1_error_2 = f1_score(y_test_error_incorrect_class, y_pred_model_6, labels=[1], average='micro')  # Error Type 2\n",
        "f1_error_3 = f1_score(y_test_error_incorrect_class, y_pred_model_6, labels=[2], average='micro')  # Error Type 3\n",
        "\n",
        "print(f\"Model VGG Evaluation:\\n\"\n",
        "      f\"F1 Score for Error Type 1: {f1_error_1}\\n\"\n",
        "      f\"F1 Score for Error Type 2: {f1_error_2}\\n\"\n",
        "      f\"F1 Score for Error Type 3: {f1_error_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "TAQ6pxFldI0M",
        "outputId": "9db8df3c-e8c9-407f-d3ba-f03292a914e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model VGG Evaluation:\n",
            "F1 Score for Error Type 1: 0.0\n",
            "F1 Score for Error Type 2: 0.918918918918919\n",
            "F1 Score for Error Type 3: 0.967032967032967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer"
      ],
      "metadata": {
        "id": "92FHQq68dMJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def build_transformer_correct_incorrect():\n",
        "    inputs = layers.Input(shape=(88, 1))\n",
        "\n",
        "    # Pass through a dense layer before the attention layer\n",
        "    x = layers.Dense(64, activation='relu')(inputs)\n",
        "\n",
        "    # Add Multi-Head Attention layer\n",
        "    attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
        "\n",
        "    # Add a residual connection and layer normalization\n",
        "    x = layers.Add()([x, attention_output])\n",
        "    x = layers.LayerNormalization()(x)\n",
        "\n",
        "    # Apply Global Average Pooling\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Dense layers\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Define and compile the model\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Step 1: Build the model\n",
        "model_7 = build_transformer_correct_incorrect()\n",
        "\n",
        "# Step 2: Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "# Step 3: Train the model\n",
        "history_7 = model_7.fit(\n",
        "    X_train, y_train_correct,\n",
        "    validation_data=(X_test, y_test_correct),\n",
        "    epochs=1000, batch_size=32, callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model_7.save('/content/transformer_pose-label.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YnevXjBdNkw",
        "outputId": "11d33bca-0549-49e4-fad2-4ca307b3818f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.6487 - loss: 0.6571 - val_accuracy: 0.6967 - val_loss: 0.6064\n",
            "Epoch 2/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6480 - loss: 0.6468 - val_accuracy: 0.6967 - val_loss: 0.5942\n",
            "Epoch 3/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6933 - loss: 0.6220 - val_accuracy: 0.7346 - val_loss: 0.5930\n",
            "Epoch 4/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6917 - loss: 0.6266 - val_accuracy: 0.7109 - val_loss: 0.6504\n",
            "Epoch 5/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7095 - loss: 0.6166 - val_accuracy: 0.7346 - val_loss: 0.5833\n",
            "Epoch 6/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7169 - loss: 0.6116 - val_accuracy: 0.7251 - val_loss: 0.5795\n",
            "Epoch 7/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7099 - loss: 0.6046 - val_accuracy: 0.7299 - val_loss: 0.6041\n",
            "Epoch 8/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.6991 - loss: 0.6132 - val_accuracy: 0.7299 - val_loss: 0.5719\n",
            "Epoch 9/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.6576 - loss: 0.6418 - val_accuracy: 0.7393 - val_loss: 0.5644\n",
            "Epoch 10/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7234 - loss: 0.5776 - val_accuracy: 0.7251 - val_loss: 0.5678\n",
            "Epoch 11/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.7231 - loss: 0.5656 - val_accuracy: 0.7204 - val_loss: 0.5623\n",
            "Epoch 12/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7035 - loss: 0.5808 - val_accuracy: 0.6872 - val_loss: 0.6468\n",
            "Epoch 13/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7111 - loss: 0.5990 - val_accuracy: 0.7346 - val_loss: 0.5418\n",
            "Epoch 14/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7237 - loss: 0.5661 - val_accuracy: 0.7299 - val_loss: 0.5861\n",
            "Epoch 15/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7216 - loss: 0.5715 - val_accuracy: 0.7441 - val_loss: 0.5262\n",
            "Epoch 16/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7215 - loss: 0.5501 - val_accuracy: 0.7678 - val_loss: 0.5371\n",
            "Epoch 17/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.7390 - loss: 0.5523 - val_accuracy: 0.6066 - val_loss: 0.6563\n",
            "Epoch 18/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6984 - loss: 0.5830 - val_accuracy: 0.7725 - val_loss: 0.5705\n",
            "Epoch 19/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7392 - loss: 0.5356 - val_accuracy: 0.7441 - val_loss: 0.5413\n",
            "Epoch 20/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7184 - loss: 0.5504 - val_accuracy: 0.7299 - val_loss: 0.5916\n",
            "Epoch 21/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6862 - loss: 0.6121 - val_accuracy: 0.7299 - val_loss: 0.6018\n",
            "Epoch 22/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6728 - loss: 0.6298 - val_accuracy: 0.7346 - val_loss: 0.5594\n",
            "Epoch 23/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7219 - loss: 0.5704 - val_accuracy: 0.7488 - val_loss: 0.5324\n",
            "Epoch 24/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7042 - loss: 0.5690 - val_accuracy: 0.7346 - val_loss: 0.5305\n",
            "Epoch 25/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - accuracy: 0.7227 - loss: 0.5577 - val_accuracy: 0.7204 - val_loss: 0.5371\n",
            "Epoch 26/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7047 - loss: 0.5642 - val_accuracy: 0.7488 - val_loss: 0.5200\n",
            "Epoch 27/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7366 - loss: 0.5334 - val_accuracy: 0.7393 - val_loss: 0.5503\n",
            "Epoch 28/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7267 - loss: 0.5494 - val_accuracy: 0.7678 - val_loss: 0.5329\n",
            "Epoch 29/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7608 - loss: 0.5269 - val_accuracy: 0.7393 - val_loss: 0.5212\n",
            "Epoch 30/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7441 - loss: 0.5115 - val_accuracy: 0.7441 - val_loss: 0.5321\n",
            "Epoch 31/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7487 - loss: 0.5048 - val_accuracy: 0.7441 - val_loss: 0.5658\n",
            "Epoch 32/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.7217 - loss: 0.5706 - val_accuracy: 0.7630 - val_loss: 0.5259\n",
            "Epoch 33/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7572 - loss: 0.5093 - val_accuracy: 0.7441 - val_loss: 0.5295\n",
            "Epoch 34/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7539 - loss: 0.5152 - val_accuracy: 0.7488 - val_loss: 0.5232\n",
            "Epoch 35/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7398 - loss: 0.5405 - val_accuracy: 0.7536 - val_loss: 0.5189\n",
            "Epoch 36/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7556 - loss: 0.5144 - val_accuracy: 0.7251 - val_loss: 0.5430\n",
            "Epoch 37/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7139 - loss: 0.5467 - val_accuracy: 0.7393 - val_loss: 0.5256\n",
            "Epoch 38/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.7435 - loss: 0.5189 - val_accuracy: 0.7488 - val_loss: 0.5293\n",
            "Epoch 39/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.7420 - loss: 0.5108 - val_accuracy: 0.7299 - val_loss: 0.5225\n",
            "Epoch 40/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7456 - loss: 0.5037 - val_accuracy: 0.7488 - val_loss: 0.5121\n",
            "Epoch 41/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7556 - loss: 0.5090 - val_accuracy: 0.7393 - val_loss: 0.5302\n",
            "Epoch 42/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7330 - loss: 0.5600 - val_accuracy: 0.7488 - val_loss: 0.5183\n",
            "Epoch 43/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7232 - loss: 0.5422 - val_accuracy: 0.7488 - val_loss: 0.5171\n",
            "Epoch 44/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7292 - loss: 0.5283 - val_accuracy: 0.7346 - val_loss: 0.5157\n",
            "Epoch 45/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.7174 - loss: 0.5412 - val_accuracy: 0.7441 - val_loss: 0.5215\n",
            "Epoch 46/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.7299 - loss: 0.5264 - val_accuracy: 0.7630 - val_loss: 0.5120\n",
            "Epoch 47/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7685 - loss: 0.4971 - val_accuracy: 0.7441 - val_loss: 0.5077\n",
            "Epoch 48/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7288 - loss: 0.5267 - val_accuracy: 0.7204 - val_loss: 0.5443\n",
            "Epoch 49/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7367 - loss: 0.5386 - val_accuracy: 0.7393 - val_loss: 0.5565\n",
            "Epoch 50/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7136 - loss: 0.5565 - val_accuracy: 0.7630 - val_loss: 0.5157\n",
            "Epoch 51/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7287 - loss: 0.5300 - val_accuracy: 0.7630 - val_loss: 0.5112\n",
            "Epoch 52/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.7369 - loss: 0.5397 - val_accuracy: 0.7346 - val_loss: 0.5414\n",
            "Epoch 53/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.7388 - loss: 0.5240 - val_accuracy: 0.7441 - val_loss: 0.5157\n",
            "Epoch 54/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.7387 - loss: 0.5091 - val_accuracy: 0.7014 - val_loss: 0.5760\n",
            "Epoch 55/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7577 - loss: 0.5179 - val_accuracy: 0.7441 - val_loss: 0.5410\n",
            "Epoch 56/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7449 - loss: 0.5217 - val_accuracy: 0.7536 - val_loss: 0.5242\n",
            "Epoch 57/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7412 - loss: 0.5334 - val_accuracy: 0.7346 - val_loss: 0.5163\n",
            "Epoch 58/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7577 - loss: 0.4913 - val_accuracy: 0.6967 - val_loss: 0.5879\n",
            "Epoch 59/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7127 - loss: 0.5958 - val_accuracy: 0.7536 - val_loss: 0.5157\n",
            "Epoch 60/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.7363 - loss: 0.5261 - val_accuracy: 0.7536 - val_loss: 0.5104\n",
            "Epoch 61/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7842 - loss: 0.4907 - val_accuracy: 0.7488 - val_loss: 0.5210\n",
            "Epoch 62/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7412 - loss: 0.5168 - val_accuracy: 0.7488 - val_loss: 0.5227\n",
            "Epoch 63/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7567 - loss: 0.5140 - val_accuracy: 0.7488 - val_loss: 0.5142\n",
            "Epoch 64/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7238 - loss: 0.5363 - val_accuracy: 0.7678 - val_loss: 0.5075\n",
            "Epoch 65/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7365 - loss: 0.5105 - val_accuracy: 0.7488 - val_loss: 0.5315\n",
            "Epoch 66/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.7530 - loss: 0.5023 - val_accuracy: 0.7204 - val_loss: 0.5320\n",
            "Epoch 67/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.7464 - loss: 0.4955 - val_accuracy: 0.7014 - val_loss: 0.6374\n",
            "Epoch 68/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7132 - loss: 0.5873 - val_accuracy: 0.7583 - val_loss: 0.5267\n",
            "Epoch 69/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7629 - loss: 0.4959 - val_accuracy: 0.7299 - val_loss: 0.5171\n",
            "Epoch 70/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7241 - loss: 0.5322 - val_accuracy: 0.7441 - val_loss: 0.5085\n",
            "Epoch 71/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7268 - loss: 0.5128 - val_accuracy: 0.7346 - val_loss: 0.5233\n",
            "Epoch 72/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7546 - loss: 0.5078 - val_accuracy: 0.7536 - val_loss: 0.5438\n",
            "Epoch 73/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.7200 - loss: 0.5598 - val_accuracy: 0.7583 - val_loss: 0.5129\n",
            "Epoch 74/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7624 - loss: 0.4859 - val_accuracy: 0.7393 - val_loss: 0.5191\n",
            "Epoch 75/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7251 - loss: 0.5198 - val_accuracy: 0.7583 - val_loss: 0.5271\n",
            "Epoch 76/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7273 - loss: 0.5222 - val_accuracy: 0.7583 - val_loss: 0.5081\n",
            "Epoch 77/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7524 - loss: 0.5058 - val_accuracy: 0.7441 - val_loss: 0.5429\n",
            "Epoch 78/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7423 - loss: 0.5409 - val_accuracy: 0.7393 - val_loss: 0.5178\n",
            "Epoch 79/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.7645 - loss: 0.5038 - val_accuracy: 0.7393 - val_loss: 0.5252\n",
            "Epoch 80/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7514 - loss: 0.5020 - val_accuracy: 0.7346 - val_loss: 0.5565\n",
            "Epoch 81/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7872 - loss: 0.4801 - val_accuracy: 0.7299 - val_loss: 0.5268\n",
            "Epoch 82/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7644 - loss: 0.5114 - val_accuracy: 0.7488 - val_loss: 0.5069\n",
            "Epoch 83/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7388 - loss: 0.5113 - val_accuracy: 0.7393 - val_loss: 0.5215\n",
            "Epoch 84/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7480 - loss: 0.5109 - val_accuracy: 0.7536 - val_loss: 0.5135\n",
            "Epoch 85/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.7382 - loss: 0.5216 - val_accuracy: 0.7393 - val_loss: 0.5007\n",
            "Epoch 86/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7493 - loss: 0.5095 - val_accuracy: 0.7393 - val_loss: 0.5272\n",
            "Epoch 87/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7427 - loss: 0.5317 - val_accuracy: 0.7441 - val_loss: 0.5047\n",
            "Epoch 88/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7410 - loss: 0.5230 - val_accuracy: 0.7630 - val_loss: 0.5069\n",
            "Epoch 89/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7704 - loss: 0.4854 - val_accuracy: 0.7488 - val_loss: 0.5206\n",
            "Epoch 90/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7432 - loss: 0.5173 - val_accuracy: 0.7678 - val_loss: 0.5090\n",
            "Epoch 91/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7518 - loss: 0.5152 - val_accuracy: 0.7630 - val_loss: 0.5244\n",
            "Epoch 92/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.7651 - loss: 0.4978 - val_accuracy: 0.7536 - val_loss: 0.4962\n",
            "Epoch 93/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.7393 - loss: 0.5221 - val_accuracy: 0.7725 - val_loss: 0.5056\n",
            "Epoch 94/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7689 - loss: 0.4859 - val_accuracy: 0.7299 - val_loss: 0.5391\n",
            "Epoch 95/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7503 - loss: 0.5163 - val_accuracy: 0.7299 - val_loss: 0.5118\n",
            "Epoch 96/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7580 - loss: 0.4942 - val_accuracy: 0.7299 - val_loss: 0.5406\n",
            "Epoch 97/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7432 - loss: 0.5291 - val_accuracy: 0.7488 - val_loss: 0.5092\n",
            "Epoch 98/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.7475 - loss: 0.4909 - val_accuracy: 0.7488 - val_loss: 0.5140\n",
            "Epoch 99/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.7479 - loss: 0.5188 - val_accuracy: 0.7630 - val_loss: 0.5080\n",
            "Epoch 100/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.7360 - loss: 0.4988 - val_accuracy: 0.7583 - val_loss: 0.5106\n",
            "Epoch 101/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7620 - loss: 0.4853 - val_accuracy: 0.7536 - val_loss: 0.5057\n",
            "Epoch 102/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7450 - loss: 0.5181 - val_accuracy: 0.7536 - val_loss: 0.5091\n",
            "Epoch 103/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7678 - loss: 0.4929 - val_accuracy: 0.7678 - val_loss: 0.4954\n",
            "Epoch 104/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7602 - loss: 0.4987 - val_accuracy: 0.7441 - val_loss: 0.5016\n",
            "Epoch 105/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7727 - loss: 0.4973 - val_accuracy: 0.7536 - val_loss: 0.4966\n",
            "Epoch 106/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.7747 - loss: 0.4610 - val_accuracy: 0.7536 - val_loss: 0.5145\n",
            "Epoch 107/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7808 - loss: 0.4733 - val_accuracy: 0.7488 - val_loss: 0.4976\n",
            "Epoch 108/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7515 - loss: 0.5183 - val_accuracy: 0.7156 - val_loss: 0.5662\n",
            "Epoch 109/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7197 - loss: 0.5483 - val_accuracy: 0.7488 - val_loss: 0.5102\n",
            "Epoch 110/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7638 - loss: 0.4907 - val_accuracy: 0.7725 - val_loss: 0.4933\n",
            "Epoch 111/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7699 - loss: 0.4813 - val_accuracy: 0.7725 - val_loss: 0.4888\n",
            "Epoch 112/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.7492 - loss: 0.5122 - val_accuracy: 0.7441 - val_loss: 0.4880\n",
            "Epoch 113/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.7479 - loss: 0.4896 - val_accuracy: 0.7299 - val_loss: 0.5340\n",
            "Epoch 114/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7479 - loss: 0.5080 - val_accuracy: 0.7630 - val_loss: 0.5012\n",
            "Epoch 115/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7611 - loss: 0.4808 - val_accuracy: 0.7678 - val_loss: 0.4841\n",
            "Epoch 116/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7526 - loss: 0.4963 - val_accuracy: 0.7583 - val_loss: 0.4988\n",
            "Epoch 117/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7739 - loss: 0.4703 - val_accuracy: 0.7204 - val_loss: 0.5890\n",
            "Epoch 118/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7615 - loss: 0.5170 - val_accuracy: 0.7346 - val_loss: 0.5403\n",
            "Epoch 119/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7661 - loss: 0.4913 - val_accuracy: 0.7725 - val_loss: 0.4857\n",
            "Epoch 120/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7606 - loss: 0.5059 - val_accuracy: 0.7488 - val_loss: 0.5023\n",
            "Epoch 121/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7749 - loss: 0.4774 - val_accuracy: 0.7441 - val_loss: 0.4955\n",
            "Epoch 122/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7476 - loss: 0.5039 - val_accuracy: 0.7630 - val_loss: 0.4945\n",
            "Epoch 123/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7715 - loss: 0.5002 - val_accuracy: 0.7678 - val_loss: 0.4848\n",
            "Epoch 124/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7714 - loss: 0.4784 - val_accuracy: 0.7441 - val_loss: 0.5083\n",
            "Epoch 125/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7469 - loss: 0.5130 - val_accuracy: 0.7536 - val_loss: 0.5093\n",
            "Epoch 126/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7642 - loss: 0.4983 - val_accuracy: 0.7488 - val_loss: 0.4817\n",
            "Epoch 127/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.7673 - loss: 0.4763 - val_accuracy: 0.7346 - val_loss: 0.5516\n",
            "Epoch 128/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7881 - loss: 0.4507 - val_accuracy: 0.7536 - val_loss: 0.4738\n",
            "Epoch 129/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7596 - loss: 0.4773 - val_accuracy: 0.7251 - val_loss: 0.6153\n",
            "Epoch 130/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7133 - loss: 0.6110 - val_accuracy: 0.7299 - val_loss: 0.5149\n",
            "Epoch 131/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7643 - loss: 0.4839 - val_accuracy: 0.7441 - val_loss: 0.5074\n",
            "Epoch 132/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7308 - loss: 0.4988 - val_accuracy: 0.6967 - val_loss: 0.5875\n",
            "Epoch 133/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7563 - loss: 0.4926 - val_accuracy: 0.7393 - val_loss: 0.5061\n",
            "Epoch 134/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.7646 - loss: 0.4561 - val_accuracy: 0.7441 - val_loss: 0.5158\n",
            "Epoch 135/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7537 - loss: 0.4993 - val_accuracy: 0.7583 - val_loss: 0.4992\n",
            "Epoch 136/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7532 - loss: 0.5175 - val_accuracy: 0.7441 - val_loss: 0.4931\n",
            "Epoch 137/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7521 - loss: 0.4780 - val_accuracy: 0.7346 - val_loss: 0.4953\n",
            "Epoch 138/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7764 - loss: 0.4493 - val_accuracy: 0.7393 - val_loss: 0.4954\n",
            "Epoch 139/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7643 - loss: 0.4831 - val_accuracy: 0.7725 - val_loss: 0.4773\n",
            "Epoch 140/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7733 - loss: 0.4858 - val_accuracy: 0.7441 - val_loss: 0.5209\n",
            "Epoch 141/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.7812 - loss: 0.4929 - val_accuracy: 0.7299 - val_loss: 0.5587\n",
            "Epoch 142/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7380 - loss: 0.5669 - val_accuracy: 0.7536 - val_loss: 0.5202\n",
            "Epoch 143/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7756 - loss: 0.4878 - val_accuracy: 0.7678 - val_loss: 0.4974\n",
            "Epoch 144/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7703 - loss: 0.4726 - val_accuracy: 0.7725 - val_loss: 0.4868\n",
            "Epoch 145/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7986 - loss: 0.4402 - val_accuracy: 0.7346 - val_loss: 0.5063\n",
            "Epoch 146/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.7496 - loss: 0.5306 - val_accuracy: 0.7725 - val_loss: 0.4826\n",
            "Epoch 147/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7530 - loss: 0.4790 - val_accuracy: 0.7536 - val_loss: 0.5185\n",
            "Epoch 148/1000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7871 - loss: 0.4750 - val_accuracy: 0.7725 - val_loss: 0.4860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "# Model 1 predictions\n",
        "y_pred_model_7 = model_7.predict(X_test)  # Assuming 'model_1' is the trained model\n",
        "y_pred_model_7 = (y_pred_model_7 > 0.5)  # If binary classification, otherwise use softmax for multi-class\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_correct, y_pred_model_7)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test_correct, y_pred_model_7)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_test_correct, y_pred_model_7)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test_correct, y_pred_model_7)\n",
        "\n",
        "print(f\"Model Transformer Evaluation:\\n\"\n",
        "      f\"Accuracy: {accuracy}\\n\"\n",
        "      f\"Precision: {precision}\\n\"\n",
        "      f\"Recall: {recall}\\n\"\n",
        "      f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubvuNTmPeZdP",
        "outputId": "88075cf6-4f64-4884-9c85-cfbc6480f235"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n",
            "Model Transformer Evaluation:\n",
            "Accuracy: 0.7535545023696683\n",
            "Precision: 0.7987421383647799\n",
            "Recall: 0.8639455782312925\n",
            "F1 Score: 0.8300653594771242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def build_transformer_error_classification():\n",
        "    inputs = layers.Input(shape=(88, 1))\n",
        "\n",
        "    # Pass through a dense layer before the attention layer\n",
        "    x = layers.Dense(64, activation='relu')(inputs)\n",
        "\n",
        "    # Add Multi-Head Attention layer\n",
        "    attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
        "\n",
        "    # Add a residual connection and layer normalization\n",
        "    x = layers.Add()([x, attention_output])\n",
        "    x = layers.LayerNormalization()(x)\n",
        "\n",
        "    # Apply Global Average Pooling\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Dense layers\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    outputs = layers.Dense(3, activation='softmax')(x)  # Adjust to 3 output classes\n",
        "\n",
        "    # Define and compile the model\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Filter only incorrect samples for training Model 2\n",
        "X_train_incorrect = X_train[y_train_correct == 0]\n",
        "X_test_incorrect = X_test[y_test_correct == 0]\n",
        "y_train_error_incorrect = y_train_error[y_train_correct == 0]\n",
        "y_test_error_incorrect = y_test_error[y_test_correct == 0]\n",
        "\n",
        "# Check and reshape if necessary\n",
        "print(f\"Shape of y_train_error_incorrect before one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect before one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Only apply one-hot encoding if they are not already encoded\n",
        "if len(y_train_error_incorrect.shape) == 1:\n",
        "    y_train_error_incorrect = to_categorical(y_train_error_incorrect, num_classes=3)\n",
        "    y_test_error_incorrect = to_categorical(y_test_error_incorrect, num_classes=3)\n",
        "\n",
        "# Check shapes after one-hot encoding\n",
        "print(f\"Shape of y_train_error_incorrect after one-hot encoding: {y_train_error_incorrect.shape}\")\n",
        "print(f\"Shape of y_test_error_incorrect after one-hot encoding: {y_test_error_incorrect.shape}\")\n",
        "\n",
        "# Train the model\n",
        "model_8 = build_transformer_error_classification()\n",
        "\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "history_8 = model_8.fit(\n",
        "    X_train_incorrect, y_train_error_incorrect,\n",
        "    validation_data=(X_test_incorrect, y_test_error_incorrect),\n",
        "    epochs=50, batch_size=32\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model_8.save('/content/transformer_error-label.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9fP2TMOecyw",
        "outputId": "8a139e4f-563e-415e-f0be-dbde0070fd87"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train_error_incorrect before one-hot encoding: (294, 3)\n",
            "Shape of y_test_error_incorrect before one-hot encoding: (64, 3)\n",
            "Shape of y_train_error_incorrect after one-hot encoding: (294, 3)\n",
            "Shape of y_test_error_incorrect after one-hot encoding: (64, 3)\n",
            "Epoch 1/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.5501 - loss: 0.8157 - val_accuracy: 0.7188 - val_loss: 0.6127\n",
            "Epoch 2/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.5811 - loss: 0.6727 - val_accuracy: 0.7188 - val_loss: 0.5841\n",
            "Epoch 3/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.6289 - loss: 0.6723 - val_accuracy: 0.7188 - val_loss: 0.5953\n",
            "Epoch 4/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6359 - loss: 0.6293 - val_accuracy: 0.3750 - val_loss: 0.8286\n",
            "Epoch 5/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.4906 - loss: 0.7417 - val_accuracy: 0.7188 - val_loss: 0.5763\n",
            "Epoch 6/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5679 - loss: 0.6583 - val_accuracy: 0.7188 - val_loss: 0.5758\n",
            "Epoch 7/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6007 - loss: 0.6877 - val_accuracy: 0.5469 - val_loss: 0.6726\n",
            "Epoch 8/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.5413 - loss: 0.6691 - val_accuracy: 0.7188 - val_loss: 0.5770\n",
            "Epoch 9/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.5956 - loss: 0.6327 - val_accuracy: 0.7969 - val_loss: 0.6153\n",
            "Epoch 10/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6529 - loss: 0.6252 - val_accuracy: 0.7344 - val_loss: 0.6154\n",
            "Epoch 11/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6925 - loss: 0.6326 - val_accuracy: 0.6562 - val_loss: 0.5812\n",
            "Epoch 12/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7144 - loss: 0.6039 - val_accuracy: 0.5781 - val_loss: 0.6439\n",
            "Epoch 13/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6611 - loss: 0.6151 - val_accuracy: 0.7812 - val_loss: 0.5974\n",
            "Epoch 14/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.6824 - loss: 0.6341 - val_accuracy: 0.7031 - val_loss: 0.5739\n",
            "Epoch 15/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6417 - loss: 0.6268 - val_accuracy: 0.6875 - val_loss: 0.6230\n",
            "Epoch 16/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6054 - loss: 0.6539 - val_accuracy: 0.5312 - val_loss: 0.6914\n",
            "Epoch 17/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.6389 - loss: 0.6340 - val_accuracy: 0.7031 - val_loss: 0.5753\n",
            "Epoch 18/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.6293 - loss: 0.6357 - val_accuracy: 0.7500 - val_loss: 0.6122\n",
            "Epoch 19/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6733 - loss: 0.6362 - val_accuracy: 0.6875 - val_loss: 0.6240\n",
            "Epoch 20/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.6386 - loss: 0.6504 - val_accuracy: 0.6406 - val_loss: 0.5782\n",
            "Epoch 21/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6066 - loss: 0.6319 - val_accuracy: 0.7344 - val_loss: 0.6124\n",
            "Epoch 22/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7414 - loss: 0.6066 - val_accuracy: 0.7812 - val_loss: 0.6006\n",
            "Epoch 23/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7589 - loss: 0.6160 - val_accuracy: 0.7344 - val_loss: 0.6157\n",
            "Epoch 24/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6945 - loss: 0.6249 - val_accuracy: 0.6719 - val_loss: 0.5742\n",
            "Epoch 25/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5960 - loss: 0.6453 - val_accuracy: 0.6562 - val_loss: 0.6300\n",
            "Epoch 26/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6918 - loss: 0.6219 - val_accuracy: 0.6406 - val_loss: 0.5802\n",
            "Epoch 27/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7085 - loss: 0.6200 - val_accuracy: 0.6406 - val_loss: 0.5778\n",
            "Epoch 28/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5999 - loss: 0.6451 - val_accuracy: 0.5469 - val_loss: 0.6588\n",
            "Epoch 29/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.6000 - loss: 0.6530 - val_accuracy: 0.7188 - val_loss: 0.5692\n",
            "Epoch 30/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.6038 - loss: 0.6446 - val_accuracy: 0.5469 - val_loss: 0.6601\n",
            "Epoch 31/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6864 - loss: 0.6199 - val_accuracy: 0.7188 - val_loss: 0.5699\n",
            "Epoch 32/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6571 - loss: 0.6416 - val_accuracy: 0.5469 - val_loss: 0.6669\n",
            "Epoch 33/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6268 - loss: 0.6340 - val_accuracy: 0.7812 - val_loss: 0.5911\n",
            "Epoch 34/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.6655 - loss: 0.6153 - val_accuracy: 0.6875 - val_loss: 0.6249\n",
            "Epoch 35/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6617 - loss: 0.6270 - val_accuracy: 0.6719 - val_loss: 0.5820\n",
            "Epoch 36/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.6546 - loss: 0.6161 - val_accuracy: 0.7812 - val_loss: 0.6078\n",
            "Epoch 37/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7163 - loss: 0.6056 - val_accuracy: 0.7500 - val_loss: 0.6110\n",
            "Epoch 38/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7330 - loss: 0.6194 - val_accuracy: 0.6406 - val_loss: 0.5816\n",
            "Epoch 39/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.6053 - loss: 0.6220 - val_accuracy: 0.5625 - val_loss: 0.6541\n",
            "Epoch 40/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.5891 - loss: 0.6397 - val_accuracy: 0.6875 - val_loss: 0.5835\n",
            "Epoch 41/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6202 - loss: 0.6345 - val_accuracy: 0.7188 - val_loss: 0.6153\n",
            "Epoch 42/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6461 - loss: 0.6214 - val_accuracy: 0.7812 - val_loss: 0.5885\n",
            "Epoch 43/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7100 - loss: 0.6382 - val_accuracy: 0.6406 - val_loss: 0.5725\n",
            "Epoch 44/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6111 - loss: 0.6159 - val_accuracy: 0.7500 - val_loss: 0.6033\n",
            "Epoch 45/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6086 - val_accuracy: 0.7812 - val_loss: 0.5842\n",
            "Epoch 46/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7476 - loss: 0.6112 - val_accuracy: 0.7812 - val_loss: 0.5842\n",
            "Epoch 47/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6523 - loss: 0.6134 - val_accuracy: 0.5938 - val_loss: 0.6371\n",
            "Epoch 48/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.5872 - loss: 0.6473 - val_accuracy: 0.7188 - val_loss: 0.5757\n",
            "Epoch 49/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.5786 - loss: 0.6611 - val_accuracy: 0.7812 - val_loss: 0.6121\n",
            "Epoch 50/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.7044 - loss: 0.6210 - val_accuracy: 0.7969 - val_loss: 0.6010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convert true labels to class indices if they are one-hot encoded\n",
        "y_test_error_incorrect_class = np.argmax(y_test_error_incorrect, axis=1)\n",
        "\n",
        "# Model 2 predictions (assuming the model outputs class probabilities)\n",
        "y_pred_model_8 = model_8.predict(X_test_incorrect)  # Your model's predictions\n",
        "y_pred_model_8 = np.argmax(y_pred_model_8, axis=1)  # Convert predictions to class indices\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_error_incorrect_class, y_pred_model_8)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'],\n",
        "            yticklabels=['Error Type 1', 'Error Type 2', 'Error Type 3'])\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# F1-score for each error type (class)\n",
        "f1_error_1 = f1_score(y_test_error_incorrect_class, y_pred_model_8, labels=[0], average='micro')  # Error Type 1\n",
        "f1_error_2 = f1_score(y_test_error_incorrect_class, y_pred_model_8, labels=[1], average='micro')  # Error Type 2\n",
        "f1_error_3 = f1_score(y_test_error_incorrect_class, y_pred_model_8, labels=[2], average='micro')  # Error Type 3\n",
        "\n",
        "print(f\"Model Transformer Evaluation:\\n\"\n",
        "      f\"F1 Score for Error Type 1: {f1_error_1}\\n\"\n",
        "      f\"F1 Score for Error Type 2: {f1_error_2}\\n\"\n",
        "      f\"F1 Score for Error Type 3: {f1_error_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "-paSXtOxfDvg",
        "outputId": "455d9ecf-be78-49a6-96de-a7e9a3a093b9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Transformer Evaluation:\n",
            "F1 Score for Error Type 1: 0.0\n",
            "F1 Score for Error Type 2: 0.6486486486486487\n",
            "F1 Score for Error Type 3: 0.8571428571428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bEYNRZmjfUa3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}